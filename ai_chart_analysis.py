#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI ì œë¯¸ë‚˜ì´ë¥¼ í™œìš©í•œ ì£¼ì‹ ì°¨íŠ¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰ ì§€ì›)
"""

import os
import json
import base64
import time
from datetime import datetime
import google.generativeai as genai
from PIL import Image
import requests
from typing import Dict, Any, Optional
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.shared import OxmlElement, qn
import pandas as pd

class StockNameMapper:
    """ì¢…ëª©ë²ˆí˜¸ì™€ ì¢…ëª©ëª… ë§¤í•‘ í´ë˜ìŠ¤"""
    
    def __init__(self, stock_list_file: str = "sotck_list.txt"):
        """
        ì¢…ëª©ëª… ë§¤í¼ ì´ˆê¸°í™”
        
        Args:
            stock_list_file (str): ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        """
        self.stock_list_file = stock_list_file
        self.stock_mapping = {}
        self.load_stock_mapping()
    
    def load_stock_mapping(self):
        """ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¢…ëª©ë²ˆí˜¸ì™€ ì¢…ëª©ëª… ë§¤í•‘ ë¡œë“œ"""
        try:
            if os.path.exists(self.stock_list_file):
                with open(self.stock_list_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and '\t' in line:
                            parts = line.split('\t')
                            if len(parts) >= 2:
                                stock_code = parts[0].strip()
                                stock_name = parts[1].strip()
                                self.stock_mapping[stock_code] = stock_name
                
                print(f"âœ… ì¢…ëª© ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(self.stock_mapping)}ê°œ ì¢…ëª©")
            else:
                print(f"âš ï¸ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.stock_list_file}")
        except Exception as e:
            print(f"âŒ ì¢…ëª© ë§¤í•‘ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_stock_name(self, stock_code: str) -> str:
        """
        ì¢…ëª©ë²ˆí˜¸ë¡œ ì¢…ëª©ëª… ì¡°íšŒ
        
        Args:
            stock_code (str): ì¢…ëª©ë²ˆí˜¸
            
        Returns:
            str: ì¢…ëª©ëª… (ì°¾ì§€ ëª»í•œ ê²½ìš° ì¢…ëª©ë²ˆí˜¸ ë°˜í™˜)
        """
        # ì¢…ëª©ë²ˆí˜¸ ì •ë¦¬ (ì•ì˜ 0 ì œê±°)
        clean_code = stock_code.lstrip('0')
        if not clean_code:
            clean_code = '0'
        
        # 6ìë¦¬ë¡œ íŒ¨ë”©
        padded_code = clean_code.zfill(6)
        
        # ë§¤í•‘ì—ì„œ ì°¾ê¸°
        if padded_code in self.stock_mapping:
            return self.stock_mapping[padded_code]
        
        # ì›ë³¸ ì½”ë“œë¡œë„ ì‹œë„
        if stock_code in self.stock_mapping:
            return self.stock_mapping[stock_code]
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° ì¢…ëª©ë²ˆí˜¸ ë°˜í™˜
        return stock_code
    
    def extract_stock_info_from_filename(self, filename: str) -> tuple:
        """
        íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì •ë³´ ì¶”ì¶œ
        
        Args:
            filename (str): íŒŒì¼ëª…
            
        Returns:
            tuple: (ì¢…ëª©ëª…, ì¢…ëª©ë²ˆí˜¸)
        """
        try:
            # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
            name_without_ext = os.path.splitext(filename)[0]
            
            # ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë¶„ë¦¬
            parts = name_without_ext.split('_')
            
            stock_name = ""
            stock_code = ""
            
            # íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„
            if len(parts) >= 3:
                # weekly_Samsung_Electronics_Co.,_Ltd._005930_20250804 í˜•íƒœ
                # ë˜ëŠ” daily_380550_380550_20250804 í˜•íƒœ
                
                # ë§ˆì§€ë§‰ì—ì„œ ë‘ ë²ˆì§¸ ë¶€ë¶„ì´ ì¢…ëª©ë²ˆí˜¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                for i, part in enumerate(parts):
                    # 6ìë¦¬ ìˆ«ìì¸ ê²½ìš° ì¢…ëª©ë²ˆí˜¸ë¡œ ê°„ì£¼
                    if len(part) == 6 and part.isdigit():
                        stock_code = part
                        # ì¢…ëª©ë²ˆí˜¸ ì•ì˜ ë¶€ë¶„ë“¤ì„ ì¢…ëª©ëª…ìœ¼ë¡œ ì¡°í•©
                        stock_name_parts = parts[1:i] if i > 1 else parts[1:]
                        stock_name = "_".join(stock_name_parts)
                        break
                
                # ì¢…ëª©ë²ˆí˜¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, íŒŒì¼ëª…ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
                if not stock_code:
                    for part in parts:
                        if len(part) == 6 and part.isdigit():
                            stock_code = part
                            break
            
            # ì¢…ëª©ëª…ì´ ë¹„ì–´ìˆê±°ë‚˜ ì¢…ëª©ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°
            if not stock_name or not stock_code:
                # íŒŒì¼ëª…ì—ì„œ 6ìë¦¬ ìˆ«ì ì°¾ê¸°
                import re
                code_match = re.search(r'(\d{6})', filename)
                if code_match:
                    stock_code = code_match.group(1)
                    # ì¢…ëª©ë²ˆí˜¸ë¡œ ì¢…ëª©ëª… ì¡°íšŒ
                    stock_name = self.get_stock_name(stock_code)
                else:
                    # íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    stock_name = name_without_ext
                    stock_code = "000000"
            
            return stock_name, stock_code
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return filename, "000000"

class ChartAnalysisPrompts:
    """ì°¨íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_daily_prompt() -> str:
        """ì¼ë´‰ ì°¨íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
        return """
ì—­í• : ë‹¹ì‹ ì€ ì „ë¬¸ ì£¼ì‹ íŠ¸ë ˆì´ë”ì´ì ì°¨íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œì‹œëœ [ì¢…ëª©ëª…]ì˜ ì¼ë´‰ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, í•µì‹¬ì ì¸ ë¶„ì„ ê²°ê³¼ì™€ ë‹¨ê¸° íˆ¬ì ì•„ì´ë””ì–´ë¥¼ A4 ìš©ì§€ 1ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ë¶„ì„ ìˆœì„œ ë° ì¶œë ¥ í˜•ì‹:

ì¢…í•© ë¶„ì„ ì ìˆ˜:

ì¼ë´‰ ì°¨íŠ¸ì˜ ì£¼ìš” ë¶„ì„ ìš”ì†Œ(ì¶”ì„¸, ëª¨ë©˜í…€, ìˆ˜ê¸‰ ë“±)ë¥¼ ì¢…í•©í•˜ì—¬ í˜„ì¬ì˜ ë‹¨ê¸° íˆ¬ì ë§¤ë ¥ë„ë¥¼ 100ì  ë§Œì ìœ¼ë¡œ í™˜ì‚°í•˜ê³ , ê·¸ ì ìˆ˜ì™€ í•¨ê»˜ í•œ ì¤„ ìš”ì•½ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•´ ì£¼ì„¸ìš”.

ì˜¤ëŠ˜ì˜ ì¼ë´‰(Daily Candle) ìš”ì•½:

ì˜¤ëŠ˜ì˜ ì¢…ê°€ [ìˆ«ì]ì›, ë“±ë½ë¥  [ìˆ«ì]%, ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ë¥¼ ë¨¼ì € ëª…ì‹œí•´ ì£¼ì„¸ìš”.

ì´ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ í•˜ë£¨ ë™ì•ˆì˜ ê°€ê²© ì›€ì§ì„ê³¼ ì‹œì¥ì˜ ì£¼ìš” íŠ¹ì§•(ì˜ˆ: ê°­ ìƒìŠ¹/í•˜ë½, íŠ¹ì • ê°€ê²©ëŒ€ ëŒíŒŒ ì‹¤íŒ¨ ë“±)ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.

í•µì‹¬ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ìš”ì•½:

ì•„ë˜ ìš©ì–´ì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì—¬, ê° ì§€í‘œì˜ í˜„ì¬ ìƒíƒœë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„  ì •ë°°ì—´ ì—¬ë¶€: [ì˜ˆ/ì•„ë‹ˆì˜¤]. (ì •ë°°ì—´: ë‹¨ê¸° ì´ë™í‰ê· ì„ ì´ ì¥ê¸° ì´ë™í‰ê· ì„  ìœ„ì— ìœ„ì¹˜í•˜ì—¬ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°•ë ¥í•œ ì‹ í˜¸.)

ê³¨ë“  í¬ë¡œìŠ¤/ë°ë“œ í¬ë¡œìŠ¤ ë°œìƒ ì—¬ë¶€: [ì˜ˆ/ì•„ë‹ˆì˜¤]. (ê³¨ë“  í¬ë¡œìŠ¤: ë‹¨ê¸° ì´ë™í‰ê· ì„ ì´ ì¥ê¸° ì´ë™í‰ê· ì„ ì„ ìƒí–¥ ëŒíŒŒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ë§¤ìˆ˜ ì‹œê·¸ë„ë¡œ í•´ì„ë¨.)

MACD ì§€í‘œ ìƒíƒœ: [MACD ìˆ˜ì¹˜] vs [ì‹œê·¸ë„ ìˆ˜ì¹˜]. (MACD: ëª¨ë©˜í…€ê³¼ ì¶”ì„¸ë¥¼ íŒŒì•…í•˜ëŠ” ì§€í‘œ. MACD ì„ ì´ ì‹œê·¸ë„ ì„  ìœ„ì— ìˆìœ¼ë©´ ìƒìŠ¹ ëª¨ë©˜í…€ì´ ê°•í•˜ë‹¤ëŠ” ì˜ë¯¸.)

RSI ì§€í‘œ ìƒíƒœ: [RSI ìˆ˜ì¹˜]. (RSI: ìƒëŒ€ê°•ë„ì§€ìˆ˜. 0-100 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ì£¼ê°€ ê³¼ë§¤ìˆ˜(70 ì´ìƒ) ë˜ëŠ” ê³¼ë§¤ë„(30 ì´í•˜) ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„.)

ë³¼ë¦°ì €ë°´ë“œ: [ë°´ë“œ í­ ë³€í™”] (ë³¼ë¦°ì €ë°´ë“œ: ì£¼ê°€ì˜ ë³€ë™ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ. ë°´ë“œê°€ ì¢ì•„ì§€ë©´ ë³€ë™ì„± í™•ëŒ€ë¥¼, ë„“ì–´ì§€ë©´ ì¶”ì„¸ì˜ ì§€ì†ì„ ì•”ì‹œ.)

ì„¸ë¶€ ë¶„ì„ ë° ì¢…í•© íŒë‹¨:

ê°€ê²© ë° ê±°ë˜ëŸ‰:

ìµœê·¼ 5ì¼ê°„ í‰ê·  ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ ëŒ€ë¹„ ì˜¤ëŠ˜ ê±°ë˜ëŸ‰ì€ [ìˆ«ì]ì£¼ë¡œ, [í‰ê·  ëŒ€ë¹„ %] ìˆ˜ì¤€ì…ë‹ˆë‹¤.

íŠ¹ì • ê°€ê²©ëŒ€([ê°€ê²©])ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë°œìƒí•œ ì¥ëŒ€ ì–‘/ìŒë´‰ ë˜ëŠ” ëŒ€ëŸ‰ ê±°ë˜ ë´‰([ê±°ë˜ëŸ‰]ì£¼)ì˜ ì˜ë¯¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„ :

í˜„ì¬ ì£¼ê°€([ê°€ê²©])ê°€ 5ì¼ì„ ([ê°€ê²©]), 20ì¼ì„ ([ê°€ê²©]), 60ì¼ì„ ([ê°€ê²©]) ëŒ€ë¹„ ì–´ë–¤ ìœ„ì¹˜ì— ìˆëŠ”ì§€(ìœ„/ì•„ë˜) ì •í™•íˆ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„ ì´ í˜„ì¬ [ë°€ì§‘/í™•ì‚°] ìƒíƒœì´ë©°, ì´ëŠ” í–¥í›„ [ë³€ë™ì„± í™•ëŒ€/ì¶•ì†Œ] ì¤‘ ë¬´ì—‡ì„ ì‹œì‚¬í•˜ëŠ”ì§€ íŒë‹¨í•´ ì£¼ì„¸ìš”.

ëª¨ë©˜í…€ ë° ê°•ë„ (MACD, RSI):

MACD ì„ ([ìˆ˜ì¹˜])ê³¼ ì‹œê·¸ë„ ì„ ([ìˆ˜ì¹˜])ì˜ ê´€ê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ëª¨ë©˜í…€ì˜ ê°•ë„ê°€ [ê°•í•¨/ì•½í•¨]ì„ íŒë‹¨í•˜ê³ , MACD ì˜¤ì‹¤ë ˆì´í„°ì˜ ì–‘/ìŒ ì „í™˜ ì—¬ë¶€ì™€ ë³€í™”ë¥¼ í†µí•´ ì¶”ì„¸ì˜ ë°©í–¥ì„±ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

**RSI ìˆ˜ì¹˜([ìˆ˜ì¹˜])**ê°€ ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , ê°€ê²©ê³¼ ì§€í‘œ ê°„ì˜ ë‹¤ì´ë²„ì „ìŠ¤ê°€ ê´€ì°°ë˜ëŠ” ê²½ìš° ê·¸ ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ë‹¨ê¸° íˆ¬ì ì•„ì´ë””ì–´ (í•µì‹¬ ìš”ì•½):

ìœ„ì˜ ì¢…í•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, [ì¢…ëª©ëª…]ì˜ ë‹¨ê¸°ì ì¸ ì¶”ì„¸ ë° ëª¨ë©˜í…€ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì ì¬ì ì¸ ë§¤ìˆ˜/ë§¤ë„ ì‹œì ì— ëŒ€í•œ í•µì‹¬ì ì¸ íˆ¬ì ì•„ì´ë””ì–´ë¥¼ 'ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.

**ì¢…ëª©ëª… ë³€í™˜ ê·œì¹™:**
íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì˜ë¬¸ íšŒì‚¬ëª… â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - SK_hynix_Inc._000660 â†’ SKí•˜ì´ë‹‰ìŠ¤
   - Samsung_Electronics_Co.,_Ltd._005930 â†’ ì‚¼ì„±ì „ì
   - Hyundai_Motor_Company_005380 â†’ í˜„ëŒ€ì°¨
   - Kiwoom_Securities_Co.,_Ltd._039490 â†’ í‚¤ì›€ì¦ê¶Œ
   - Aurora_World_Corp_039830 â†’ ì˜¤ë¡œë¼ì›”ë“œ
   - Heng_Sheng_Holding_Group_Limited_900270 â†’ í•­ì„±í™€ë”©ê·¸ë£¹
   - ê¸°íƒ€ ì˜ë¬¸ëª…ì€ í•œêµ­ì–´ íšŒì‚¬ëª…ìœ¼ë¡œ ë³€í™˜

2. **ì¢…ëª©ì½”ë“œ â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - 380550 â†’ ë‰´ë¡œí« (Neurophet)
   - 328130 â†’ ë£¨ë‹› (Lunit)
   - 338220 â†’ Vuno
   - ì¢…ëª©ì½”ë“œë§Œ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì¢…ëª©ì˜ ì‹¤ì œ í•œêµ­ì–´ íšŒì‚¬ëª…ì„ ì°¾ì•„ì„œ ì‚¬ìš©

3. **íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„:**
   - weekly_Samsung_Electronics_Co.,_Ltd._005930_20250804.png â†’ ì‚¼ì„±ì „ì (005930)
   - daily_380550_380550_20250804.png â†’ ë‰´ë¡œí« (380550)
   - íŒŒì¼ëª…ì—ì„œ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ êµ¬ë¶„ëœ ë¶€ë¶„ë“¤ì„ ë¶„ì„í•˜ì—¬ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ

4. **ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©ì˜ ê²½ìš°:**
   - ì¢…ëª©ì½”ë“œëŠ” íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
   - ì¢…ëª©ëª…ì€ "ì•Œ ìˆ˜ ì—†ìŒ" ëŒ€ì‹  ì¢…ëª©ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ê°€ëŠ¥í•œ ê²½ìš° ì˜ë¬¸ëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜

**ì‘ë‹µ í˜•ì‹:**
JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì¼ë´‰ ì°¨íŠ¸ì— í•„ìš”í•œ ì§€í‘œë§Œ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

{
  "ì¢…ëª©ì •ë³´": {
    "ì¢…ëª©ëª…": "í•œêµ­ì–´ íšŒì‚¬ëª…",
    "ì¢…ëª©ë²ˆí˜¸": "6ìë¦¬ ì¢…ëª©ì½”ë“œ",
    "ë¶„ì„ì¼ì‹œ": "YYYY-MM-DD HH:MM:SS",
    "ì°¨íŠ¸ìœ í˜•": "ì¼ë´‰"
  },
  "ì¢…í•©ë¶„ì„ì ìˆ˜": {
    "ì ìˆ˜": 85,
    "ìš”ì•½": "ë‹¨ê¸° ìƒìŠ¹ ëª¨ë©˜í…€ ê°•í•¨, ë§¤ìˆ˜ ì‹œê·¸ë„"
  },
  "ì˜¤ëŠ˜ì˜ì¼ë´‰": {
    "ì¢…ê°€": "ê°€ê²©",
    "ë“±ë½ë¥ ": "ë“±ë½ë¥ ",
    "ê±°ë˜ëŸ‰": "ê±°ë˜ëŸ‰",
    "ì£¼ìš”íŠ¹ì§•": "ì˜¤ëŠ˜ì˜ ì£¼ìš” íŠ¹ì§•"
  },
  "í•µì‹¬ê¸°ìˆ ì ì§€í‘œ": {
    "ì´ë™í‰ê· ì„ ì •ë°°ì—´": "ì˜ˆ/ì•„ë‹ˆì˜¤",
    "ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤": "ì˜ˆ/ì•„ë‹ˆì˜¤",
    "MACDìƒíƒœ": "MACD vs ì‹œê·¸ë„",
    "RSIìƒíƒœ": "RSI ìˆ˜ì¹˜",
    "ë³¼ë¦°ì €ë°´ë“œ": "ë°´ë“œ í­ ë³€í™”"
  },
  "ì„¸ë¶€ë¶„ì„": {
    "ê°€ê²©ë°ê±°ë˜ëŸ‰": {
      "ê±°ë˜ëŸ‰ë¹„êµ": "í‰ê·  ëŒ€ë¹„ ê±°ë˜ëŸ‰",
      "ì£¼ìš”ê°€ê²©ëŒ€": "íŠ¹ì • ê°€ê²©ëŒ€ ë¶„ì„"
    },
    "ì´ë™í‰ê· ì„ ": {
      "í˜„ì¬ê°€ìœ„ì¹˜": "ì´ë™í‰ê· ì„  ëŒ€ë¹„ ìœ„ì¹˜",
      "ë°€ì§‘ë„": "ë°€ì§‘/í™•ì‚° ìƒíƒœ"
    },
    "ëª¨ë©˜í…€": {
      "MACDë¶„ì„": "ëª¨ë©˜í…€ ê°•ë„ ë¶„ì„",
      "RSIë¶„ì„": "RSI êµ¬ê°„ ë° ë‹¤ì´ë²„ì „ìŠ¤"
    }
  },
  "ë‹¨ê¸°íˆ¬ìì•„ì´ë””ì–´": {
    "ì¶”ì„¸ìš”ì•½": "ë‹¨ê¸° ì¶”ì„¸ ìš”ì•½",
    "ë§¤ë§¤ì‹œê·¸ë„": "ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„"
  }
}
"""

    @staticmethod
    def get_weekly_prompt() -> str:
        """ì£¼ë´‰ ì°¨íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
        return """
ì—­í• : ë‹¹ì‹ ì€ ì „ë¬¸ ì£¼ì‹ íŠ¸ë ˆì´ë”ì´ì ì°¨íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œì‹œëœ [ì¢…ëª©ëª…]ì˜ ì£¼ë´‰ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì¤‘ê¸°ì ì¸ íˆ¬ì ì•„ì´ë””ì–´ë¥¼ A4 ìš©ì§€ 1ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ë¶„ì„ ìˆœì„œ ë° ì¶œë ¥ í˜•ì‹:

ì¢…í•© ë¶„ì„ ì ìˆ˜:

ì£¼ë´‰ ì°¨íŠ¸ì˜ ì£¼ìš” ë¶„ì„ ìš”ì†Œë“¤ì„ ì¢…í•©í•˜ì—¬ í˜„ì¬ì˜ ì¤‘ê¸° íˆ¬ì ë§¤ë ¥ë„ë¥¼ 100ì  ë§Œì ìœ¼ë¡œ í™˜ì‚°í•˜ê³ , ê·¸ ì ìˆ˜ì™€ í•¨ê»˜ í•œ ì¤„ ìš”ì•½ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•´ ì£¼ì„¸ìš”.

ì´ë²ˆ ì£¼ ë´‰(Weekly Candle) ìš”ì•½:

ì´ë²ˆ ì£¼ì˜ ì¢…ê°€ [ìˆ«ì]ì›, ë“±ë½ë¥  [ìˆ«ì]%, ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ë¥¼ ë¨¼ì € ëª…ì‹œí•´ ì£¼ì„¸ìš”.

ì´ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ë‚œ í•œ ì£¼ ë™ì•ˆì˜ ê°€ê²© ì›€ì§ì„ê³¼ ì‹œì¥ì˜ ì£¼ìš” íŠ¹ì§•(ì˜ˆ: ì£¼ìš” ì§€ì§€/ì €í•­ì„  í„°ì¹˜, ë°•ìŠ¤ê¶Œ ëŒíŒŒ ì‹œë„ ë“±)ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.

í•µì‹¬ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ìš”ì•½:

ì•„ë˜ ìš©ì–´ì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì—¬, ê° ì§€í‘œì˜ í˜„ì¬ ìƒíƒœë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„  ì •ë°°ì—´ ì—¬ë¶€: [ì˜ˆ/ì•„ë‹ˆì˜¤]. (ì •ë°°ì—´: ë‹¨ê¸° ì´ë™í‰ê· ì„ ì´ ì¥ê¸° ì´ë™í‰ê· ì„  ìœ„ì— ìœ„ì¹˜í•˜ì—¬ ì¤‘ê¸° ìƒìŠ¹ ì¶”ì„¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì‹ í˜¸.)

ê³¨ë“  í¬ë¡œìŠ¤/ë°ë“œ í¬ë¡œìŠ¤ ë°œìƒ ì—¬ë¶€: [ì˜ˆ/ì•„ë‹ˆì˜¤]. (ê³¨ë“  í¬ë¡œìŠ¤: ë‹¨ê¸° ì´í‰ì„ ì´ ì¥ê¸° ì´í‰ì„ ì„ ìƒí–¥ ëŒíŒŒí•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ì¤‘ê¸°ì ì¸ ë§¤ìˆ˜ ì‹œê·¸ë„ë¡œ í•´ì„ë¨.)

Stochastic Slow ìƒíƒœ: %K: [ìˆ˜ì¹˜], %D: [ìˆ˜ì¹˜]. (Stochastic Slow: ì£¼ê°€ ì›€ì§ì„ì˜ ì†ë„ë¥¼ íŒŒì•…í•˜ëŠ” ì§€í‘œ. ê³¼ë§¤ìˆ˜(80 ì´ìƒ) ë˜ëŠ” ê³¼ë§¤ë„(20 ì´í•˜) êµ¬ê°„ ì§„ì… ì—¬ë¶€ë¡œ ë§¤ë§¤ ì‹œì ì„ íŒë‹¨.)

ë³¼ë¦°ì €ë°´ë“œ: [ë°´ë“œ í­ ë³€í™”] (ë³¼ë¦°ì €ë°´ë“œ: ì£¼ê°€ì˜ ë³€ë™ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ. ë°´ë“œ í­ì´ ì¢ì•„ì§€ë©´ ë³€ë™ì„± í™•ëŒ€ë¥¼, ë„“ì–´ì§€ë©´ ì¶”ì„¸ì˜ ì§€ì†ì„ ì•”ì‹œ.)

ì„¸ë¶€ ë¶„ì„ ë° ì¢…í•© íŒë‹¨:

ê°€ê²© ë° ê±°ë˜ëŸ‰:

ìµœê·¼ 1ê°œì›”(4ì£¼) í‰ê·  ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ ëŒ€ë¹„ ì´ë²ˆ ì£¼ ê±°ë˜ëŸ‰ì€ [ìˆ«ì]ì£¼ë¡œ, [í‰ê·  ëŒ€ë¹„ %] ìˆ˜ì¤€ì…ë‹ˆë‹¤.

[ì¢…ëª©ëª…]ì€ ìµœê·¼ [N]ì£¼ê°„ [í•˜ë‹¨ ê°€ê²©]ì›ì—ì„œ [ìƒë‹¨ ê°€ê²©]ì› ì‚¬ì´ì˜ ë°•ìŠ¤ê¶Œì„ í˜•ì„±í•˜ê³  ìˆëŠ”ì§€, ë˜ëŠ” ì´íƒˆí–ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„ :

í˜„ì¬ ì£¼ê°€([ê°€ê²©])ê°€ 5ì£¼ì„ ([ê°€ê²©]), 20ì£¼ì„ ([ê°€ê²©]), 60ì£¼ì„ ([ê°€ê²©]) ëŒ€ë¹„ ì–´ë–¤ ìœ„ì¹˜ì— ìˆëŠ”ì§€(ìœ„/ì•„ë˜) ì •í™•íˆ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.

íŠ¹íˆ 20ì£¼ì„ ì´ ì¤‘ê¸° ì¶”ì„¸ì˜ ë°©í–¥ì„±ì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ [ì§€ì§€ì„ /ì €í•­ì„ ] ì—­í• ì„ í•˜ëŠ”ì§€ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ëª¨ë©˜í…€ ë° ë³€ë™ì„± (Stochastic, Bollinger Bands):

Stochastic %K ì„ ([ìˆ˜ì¹˜])ê³¼ %D ì„ ([ìˆ˜ì¹˜])ì˜ êµì°¨ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ëª¨ë©˜í…€ì˜ ê°•ë„ê°€ [ê°•í•¨/ì•½í•¨]ì„ íŒë‹¨í•´ ì£¼ì„¸ìš”.

ë³¼ë¦°ì €ë°´ë“œì˜ í­ì´ í˜„ì¬ [ì¢ì•„ì§/ë„“ì–´ì§] ìƒíƒœì´ë©°, ì´ëŠ” í–¥í›„ [ë³€ë™ì„± í™•ëŒ€/ì¶•ì†Œ] ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•œë‹¤ê³  íŒë‹¨í•´ ì£¼ì„¸ìš”.

ì¢…í•©ì ì¸ ì¤‘ê¸° íˆ¬ì ì•„ì´ë””ì–´ (í•µì‹¬ ìš”ì•½):

ìœ„ì˜ ì¢…í•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, [ì¢…ëª©ëª…]ì˜ ì¤‘ê¸°ì ì¸ ì¶”ì„¸ ë°©í–¥ì„±ê³¼ ì£¼ìš” ì›€ì§ì„ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì ì¬ì ì¸ ë§¤ìˆ˜/ë§¤ë„ ì‹œì ì— ëŒ€í•œ í•µì‹¬ì ì¸ íˆ¬ì ì•„ì´ë””ì–´ë¥¼ 'ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„' ê°™ì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.

**ì¢…ëª©ëª… ë³€í™˜ ê·œì¹™:**
íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì˜ë¬¸ íšŒì‚¬ëª… â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - SK_hynix_Inc._000660 â†’ SKí•˜ì´ë‹‰ìŠ¤
   - Samsung_Electronics_Co.,_Ltd._005930 â†’ ì‚¼ì„±ì „ì
   - Hyundai_Motor_Company_005380 â†’ í˜„ëŒ€ì°¨
   - Kiwoom_Securities_Co.,_Ltd._039490 â†’ í‚¤ì›€ì¦ê¶Œ
   - Aurora_World_Corp_039830 â†’ ì˜¤ë¡œë¼ì›”ë“œ
   - Heng_Sheng_Holding_Group_Limited_900270 â†’ í•­ì„±í™€ë”©ê·¸ë£¹
   - ê¸°íƒ€ ì˜ë¬¸ëª…ì€ í•œêµ­ì–´ íšŒì‚¬ëª…ìœ¼ë¡œ ë³€í™˜

2. **ì¢…ëª©ì½”ë“œ â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - 380550 â†’ ë‰´ë¡œí« (Neurophet)
   - 328130 â†’ ë£¨ë‹› (Lunit)
   - 338220 â†’ Vuno
   - ì¢…ëª©ì½”ë“œë§Œ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì¢…ëª©ì˜ ì‹¤ì œ í•œêµ­ì–´ íšŒì‚¬ëª…ì„ ì°¾ì•„ì„œ ì‚¬ìš©

3. **íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„:**
   - weekly_Samsung_Electronics_Co.,_Ltd._005930_20250804.png â†’ ì‚¼ì„±ì „ì (005930)
   - daily_380550_380550_20250804.png â†’ ë‰´ë¡œí« (380550)
   - íŒŒì¼ëª…ì—ì„œ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ êµ¬ë¶„ëœ ë¶€ë¶„ë“¤ì„ ë¶„ì„í•˜ì—¬ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ

4. **ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©ì˜ ê²½ìš°:**
   - ì¢…ëª©ì½”ë“œëŠ” íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
   - ì¢…ëª©ëª…ì€ "ì•Œ ìˆ˜ ì—†ìŒ" ëŒ€ì‹  ì¢…ëª©ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ê°€ëŠ¥í•œ ê²½ìš° ì˜ë¬¸ëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜

**ì‘ë‹µ í˜•ì‹:**
JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì£¼ë´‰ ì°¨íŠ¸ì— í•„ìš”í•œ ì§€í‘œë§Œ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

{
  "ì¢…ëª©ì •ë³´": {
    "ì¢…ëª©ëª…": "í•œêµ­ì–´ íšŒì‚¬ëª…",
    "ì¢…ëª©ë²ˆí˜¸": "6ìë¦¬ ì¢…ëª©ì½”ë“œ",
    "ë¶„ì„ì¼ì‹œ": "YYYY-MM-DD HH:MM:SS",
    "ì°¨íŠ¸ìœ í˜•": "ì£¼ë´‰"
  },
  "ì¢…í•©ë¶„ì„ì ìˆ˜": {
    "ì ìˆ˜": 75,
    "ìš”ì•½": "ì¤‘ê¸° ìƒìŠ¹ ì¶”ì„¸ ìœ ì§€, ë°•ìŠ¤ê¶Œ ëŒíŒŒ ì‹œë„"
  },
  "ì´ë²ˆì£¼ë´‰": {
    "ì¢…ê°€": "ê°€ê²©",
    "ë“±ë½ë¥ ": "ë“±ë½ë¥ ",
    "ê±°ë˜ëŸ‰": "ê±°ë˜ëŸ‰",
    "ì£¼ìš”íŠ¹ì§•": "ì´ë²ˆ ì£¼ì˜ ì£¼ìš” íŠ¹ì§•"
  },
  "í•µì‹¬ê¸°ìˆ ì ì§€í‘œ": {
    "ì´ë™í‰ê· ì„ ì •ë°°ì—´": "ì˜ˆ/ì•„ë‹ˆì˜¤",
    "ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤": "ì˜ˆ/ì•„ë‹ˆì˜¤",
    "Stochasticìƒíƒœ": "%K vs %D",
    "ë³¼ë¦°ì €ë°´ë“œ": "ë°´ë“œ í­ ë³€í™”"
  },
  "ì„¸ë¶€ë¶„ì„": {
    "ê°€ê²©ë°ê±°ë˜ëŸ‰": {
      "ê±°ë˜ëŸ‰ë¹„êµ": "í‰ê·  ëŒ€ë¹„ ê±°ë˜ëŸ‰",
      "ë°•ìŠ¤ê¶Œë¶„ì„": "ë°•ìŠ¤ê¶Œ í˜•ì„± ë° ì´íƒˆ ì—¬ë¶€"
    },
    "ì´ë™í‰ê· ì„ ": {
      "í˜„ì¬ê°€ìœ„ì¹˜": "ì´ë™í‰ê· ì„  ëŒ€ë¹„ ìœ„ì¹˜",
      "20ì£¼ì„ ì—­í• ": "ì§€ì§€ì„ /ì €í•­ì„  ì—­í• "
    },
    "ëª¨ë©˜í…€": {
      "Stochasticë¶„ì„": "ëª¨ë©˜í…€ ê°•ë„ ë¶„ì„",
      "ë³¼ë¦°ì €ë°´ë“œë¶„ì„": "ë³€ë™ì„± í™•ëŒ€/ì¶•ì†Œ ë¶„ì„"
    }
  },
  "ì¤‘ê¸°íˆ¬ìì•„ì´ë””ì–´": {
    "ì¶”ì„¸ìš”ì•½": "ì¤‘ê¸° ì¶”ì„¸ ìš”ì•½",
    "ë§¤ë§¤ì‹œê·¸ë„": "ë§¤ìˆ˜/ë§¤ë„ ì‹œê·¸ë„"
  }
}
"""

    @staticmethod
    def get_monthly_prompt() -> str:
        """ì›”ë´‰ ì°¨íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
        return """
ì—­í• : ë‹¹ì‹ ì€ ì „ë¬¸ ì£¼ì‹ íŠ¸ë ˆì´ë”ì´ì ì°¨íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì— ì œì‹œëœ [ì¢…ëª©ëª…]ì˜ ì›”ë´‰ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, ì¥ê¸°ì ì¸ íˆ¬ì ì•„ì´ë””ì–´ë¥¼ A4 ìš©ì§€ 1ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ë¶„ì„ ìˆœì„œ ë° ì¶œë ¥ í˜•ì‹:

ì¢…í•© ë¶„ì„ ì ìˆ˜:

ì›”ë´‰ ì°¨íŠ¸ì˜ ì£¼ìš” ë¶„ì„ ìš”ì†Œë“¤ì„ ì¢…í•©í•˜ì—¬ í˜„ì¬ì˜ ì¥ê¸° íˆ¬ì ë§¤ë ¥ë„ë¥¼ 100ì  ë§Œì ìœ¼ë¡œ í™˜ì‚°í•˜ê³ , ê·¸ ì ìˆ˜ì™€ í•¨ê»˜ í•œ ì¤„ ìš”ì•½ì„ ê°€ì¥ ë¨¼ì € ì œì‹œí•´ ì£¼ì„¸ìš”.

ì´ë²ˆ ì›”ë´‰(Monthly Candle) ìš”ì•½:

ì´ë²ˆ ë‹¬ì˜ ì¢…ê°€ [ìˆ«ì]ì›, ë“±ë½ë¥  [ìˆ«ì]%, ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ë¥¼ ë¨¼ì € ëª…ì‹œí•´ ì£¼ì„¸ìš”.

ì´ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ë‚œ í•œ ë‹¬ ë™ì•ˆì˜ ê°€ê²© ì›€ì§ì„ê³¼ ì‹œì¥ì˜ ì£¼ìš” íŠ¹ì§•(ì˜ˆ: ì‚¬ìƒ ìµœê³ ê°€/ìµœì €ê°€ ê²½ì‹ , ì¤‘ìš”í•œ ê°€ê²©ëŒ€ í„°ì¹˜ ë“±)ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.

í•µì‹¬ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ ìš”ì•½:

ì•„ë˜ ìš©ì–´ì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì—¬, ê° ì§€í‘œì˜ í˜„ì¬ ìƒíƒœë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì¥ê¸° ì •ë°°ì—´ ì—¬ë¶€: [ì˜ˆ/ì•„ë‹ˆì˜¤]. (ì¥ê¸° ì •ë°°ì—´: ì¥ê¸° ì´ë™í‰ê· ì„ ì´ ì•ˆì •ì ì¸ ìƒìŠ¹ ì¶”ì„¸ë¥¼ ìœ ì§€í•˜ëŠ” ìƒíƒœë¡œ, ì¥ê¸° íˆ¬ì ê´€ì ì—ì„œ ê¸ì •ì ì¸ ì‹ í˜¸.)

CCI ì§€í‘œ ìƒíƒœ: [CCI ìˆ˜ì¹˜]. (CCI: ì¶”ì„¸ì˜ ì‹œì‘ê³¼ ì „í™˜ì„ íŒŒì•…í•˜ëŠ” ì§€í‘œ. ê³¼ë§¤ìˆ˜(+100 ì´ìƒ) ë˜ëŠ” ê³¼ë§¤ë„(-100 ì´í•˜) êµ¬ê°„ ì§„ì… ì—¬ë¶€ë¡œ ì¶”ì„¸ì˜ ê·¹ë‹¨ì„ íŒë‹¨.)

ADX ì§€í‘œ ìƒíƒœ: [ADX ìˆ˜ì¹˜]. (ADX: ì¶”ì„¸ì˜ ê°•ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œ. 20 ì´ìƒì´ë©´ ì¶”ì„¸ê°€ ì¡´ì¬í•˜ë©°, ìˆ˜ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ ì¶”ì„¸ê°€ ê°•í•˜ë‹¤ëŠ” ì˜ë¯¸.)

ì£¼ìš” ì´ë™í‰ê· ì„  ìœ„ì¹˜: [5ê°œì›”ì„ /10ê°œì›”ì„ /20ê°œì›”ì„ ]. (ì´ë™í‰ê· ì„ : íŠ¹ì • ê¸°ê°„ì˜ í‰ê·  ê°€ê²©ì„ ë‚˜íƒ€ë‚´ëŠ” ì„ . ì¥ê¸° ì°¨íŠ¸ì—ì„œëŠ” ì¤‘ìš”í•œ ì§€ì§€ì„ /ì €í•­ì„  ì—­í• ì„ í•¨.)

ì„¸ë¶€ ë¶„ì„ ë° ì¢…í•© íŒë‹¨:

ê°€ê²© ë° ê±°ë˜ëŸ‰:

ì§€ë‚œ 6ê°œì›”ê°„ í‰ê·  ê±°ë˜ëŸ‰ [ìˆ«ì]ì£¼ ëŒ€ë¹„ ì´ë²ˆ ë‹¬ ê±°ë˜ëŸ‰ì€ [ìˆ«ì]ì£¼ë¡œ, [í‰ê·  ëŒ€ë¹„ %] ìˆ˜ì¤€ì…ë‹ˆë‹¤.

ì°¨íŠ¸ ìƒì˜ **ì—­ì‚¬ì ì¸ ê³ ì ([ê°€ê²©])ê³¼ ì €ì ([ê°€ê²©])**ì„ ì–¸ê¸‰í•˜ë©°, í˜„ì¬ ê°€ê²©([ê°€ê²©])ì´ ì¥ê¸° ì£¼ê°€ ì‚¬ì´í´ ìƒ ì–´ëŠ ìœ„ì¹˜ì— ìˆëŠ”ì§€ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ì´ë™í‰ê· ì„ :

í˜„ì¬ ì£¼ê°€([ê°€ê²©])ê°€ 5ê°œì›”ì„ ([ê°€ê²©]), 10ê°œì›”ì„ ([ê°€ê²©]), 20ê°œì›”ì„ ([ê°€ê²©]) ëŒ€ë¹„ ì–´ë–¤ ìœ„ì¹˜ì— ìˆëŠ”ì§€(ìœ„/ì•„ë˜) ì •í™•íˆ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.

íŠ¹íˆ 20ê°œì›”ì„ ì´ ì¥ê¸° ì¶”ì„¸ì˜ ë°©í–¥ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ì¤‘ìš”í•œ [ì§€ì§€ì„ /ì €í•­ì„ ] ì—­í• ì„ í•˜ëŠ”ì§€ ë¶„ì„í•´ ì£¼ì„¸ìš”.

ëª¨ë©˜í…€ ë° ì¶”ì„¸ ê°•ë„ (CCI, ADX):

**CCI ìˆ˜ì¹˜([ìˆ˜ì¹˜])**ê°€ ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ êµ¬ê°„ì— ì§„ì…í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , 0ì„ ì„ [ìƒí–¥/í•˜í–¥] ëŒíŒŒí–ˆëŠ”ì§€ ì—¬ë¶€ì™€ ê·¸ ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

**ADX ìˆ˜ì¹˜([ìˆ˜ì¹˜])**ë¥¼ í†µí•´ í˜„ì¬ [ì¶”ì„¸ì˜ ê°•ë„ê°€ ê°•í™”/ì•½í™”]ë˜ê³  ìˆë‹¤ê³  íŒë‹¨í•˜ê³ , ì¶”ì„¸ê°€ [ìƒìŠ¹/í•˜ë½/íš¡ë³´] ì¤‘ ì–´ëŠ ë°©í–¥ìœ¼ë¡œ ë‚˜ì•„ê°€ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ì¢…í•©ì ì¸ ì¥ê¸° íˆ¬ì ì•„ì´ë””ì–´ (í•µì‹¬ ìš”ì•½):

ìœ„ì˜ ì¢…í•© ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, [ì¢…ëª©ëª…]ì˜ ì¥ê¸°ì ì¸ ì£¼ê°€ ì‚¬ì´í´ ë° ê±°ì‹œì ì¸ ì¶”ì„¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.

ì¥ê¸° íˆ¬ì ê´€ì ì—ì„œì˜ í•µì‹¬ì ì¸ ì•„ì´ë””ì–´ë¥¼ 'ì¥ê¸° ë³´ìœ ', 'ë¶„í•  ë§¤ìˆ˜', 'ê´€ë§' ë“±ì˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.

**ì¢…ëª©ëª… ë³€í™˜ ê·œì¹™:**
íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì˜ë¬¸ íšŒì‚¬ëª… â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - SK_hynix_Inc._000660 â†’ SKí•˜ì´ë‹‰ìŠ¤
   - Samsung_Electronics_Co.,_Ltd._005930 â†’ ì‚¼ì„±ì „ì
   - Hyundai_Motor_Company_005380 â†’ í˜„ëŒ€ì°¨
   - Kiwoom_Securities_Co.,_Ltd._039490 â†’ í‚¤ì›€ì¦ê¶Œ
   - Aurora_World_Corp_039830 â†’ ì˜¤ë¡œë¼ì›”ë“œ
   - Heng_Sheng_Holding_Group_Limited_900270 â†’ í•­ì„±í™€ë”©ê·¸ë£¹
   - ê¸°íƒ€ ì˜ë¬¸ëª…ì€ í•œêµ­ì–´ íšŒì‚¬ëª…ìœ¼ë¡œ ë³€í™˜

2. **ì¢…ëª©ì½”ë“œ â†’ í•œêµ­ì–´ íšŒì‚¬ëª… ë³€í™˜:**
   - 380550 â†’ ë‰´ë¡œí« (Neurophet)
   - 328130 â†’ ë£¨ë‹› (Lunit)
   - 338220 â†’ Vuno
   - ì¢…ëª©ì½”ë“œë§Œ ìˆëŠ” ê²½ìš° í•´ë‹¹ ì¢…ëª©ì˜ ì‹¤ì œ í•œêµ­ì–´ íšŒì‚¬ëª…ì„ ì°¾ì•„ì„œ ì‚¬ìš©

3. **íŒŒì¼ëª… íŒ¨í„´ ë¶„ì„:**
   - weekly_Samsung_Electronics_Co.,_Ltd._005930_20250804.png â†’ ì‚¼ì„±ì „ì (005930)
   - daily_380550_380550_20250804.png â†’ ë‰´ë¡œí« (380550)
   - íŒŒì¼ëª…ì—ì„œ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ êµ¬ë¶„ëœ ë¶€ë¶„ë“¤ì„ ë¶„ì„í•˜ì—¬ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ

4. **ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª©ì˜ ê²½ìš°:**
   - ì¢…ëª©ì½”ë“œëŠ” íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
   - ì¢…ëª©ëª…ì€ "ì•Œ ìˆ˜ ì—†ìŒ" ëŒ€ì‹  ì¢…ëª©ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ê°€ëŠ¥í•œ ê²½ìš° ì˜ë¬¸ëª…ì„ í•œêµ­ì–´ë¡œ ë³€í™˜

**ì‘ë‹µ í˜•ì‹:**
JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì›”ë´‰ ì°¨íŠ¸ì— í•„ìš”í•œ ì§€í‘œë§Œ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

{
  "ì¢…ëª©ì •ë³´": {
    "ì¢…ëª©ëª…": "í•œêµ­ì–´ íšŒì‚¬ëª…",
    "ì¢…ëª©ë²ˆí˜¸": "6ìë¦¬ ì¢…ëª©ì½”ë“œ",
    "ë¶„ì„ì¼ì‹œ": "YYYY-MM-DD HH:MM:SS",
    "ì°¨íŠ¸ìœ í˜•": "ì›”ë´‰"
  },
  "ì¢…í•©ë¶„ì„ì ìˆ˜": {
    "ì ìˆ˜": 65,
    "ìš”ì•½": "ì¥ê¸° ìƒìŠ¹ ì¶”ì„¸ ìœ ì§€, ë¶„í•  ë§¤ìˆ˜ ì ê¸°"
  },
  "ì´ë²ˆì›”ë´‰": {
    "ì¢…ê°€": "ê°€ê²©",
    "ë“±ë½ë¥ ": "ë“±ë½ë¥ ",
    "ê±°ë˜ëŸ‰": "ê±°ë˜ëŸ‰",
    "ì£¼ìš”íŠ¹ì§•": "ì´ë²ˆ ë‹¬ì˜ ì£¼ìš” íŠ¹ì§•"
  },
  "í•µì‹¬ê¸°ìˆ ì ì§€í‘œ": {
    "ì¥ê¸°ì •ë°°ì—´": "ì˜ˆ/ì•„ë‹ˆì˜¤",
    "CCIìƒíƒœ": "CCI ìˆ˜ì¹˜",
    "ADXìƒíƒœ": "ADX ìˆ˜ì¹˜",
    "ì£¼ìš”ì´ë™í‰ê· ì„ ": "5ê°œì›”ì„ /10ê°œì›”ì„ /20ê°œì›”ì„ "
  },
  "ì„¸ë¶€ë¶„ì„": {
    "ê°€ê²©ë°ê±°ë˜ëŸ‰": {
      "ê±°ë˜ëŸ‰ë¹„êµ": "í‰ê·  ëŒ€ë¹„ ê±°ë˜ëŸ‰",
      "ì—­ì‚¬ì ê³ ì ì €ì ": "ì—­ì‚¬ì  ê³ ì /ì €ì  ë¶„ì„"
    },
    "ì´ë™í‰ê· ì„ ": {
      "í˜„ì¬ê°€ìœ„ì¹˜": "ì´ë™í‰ê· ì„  ëŒ€ë¹„ ìœ„ì¹˜",
      "20ê°œì›”ì„ ì—­í• ": "ì§€ì§€ì„ /ì €í•­ì„  ì—­í• "
    },
    "ëª¨ë©˜í…€": {
      "CCIë¶„ì„": "CCI êµ¬ê°„ ë° 0ì„  ëŒíŒŒ ë¶„ì„",
      "ADXë¶„ì„": "ì¶”ì„¸ ê°•ë„ ë° ë°©í–¥ì„± ë¶„ì„"
    }
  },
  "ì¥ê¸°íˆ¬ìì•„ì´ë””ì–´": {
    "ì‚¬ì´í´ìš”ì•½": "ì¥ê¸° ì£¼ê°€ ì‚¬ì´í´ ìš”ì•½",
    "íˆ¬ìì „ëµ": "ì¥ê¸° íˆ¬ì ì „ëµ"
  }
}
"""

    @staticmethod
    def get_prompt(chart_type: str) -> str:
        """ì°¨íŠ¸ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        chart_type = chart_type.lower()
        if chart_type in ['daily', 'ì¼ë´‰', 'day']:
            return ChartAnalysisPrompts.get_daily_prompt()
        elif chart_type in ['weekly', 'ì£¼ë´‰', 'week']:
            return ChartAnalysisPrompts.get_weekly_prompt()
        elif chart_type in ['monthly', 'ì›”ë´‰', 'month']:
            return ChartAnalysisPrompts.get_monthly_prompt()
        else:
            # ê¸°ë³¸ê°’ì€ ì¼ë´‰
            return ChartAnalysisPrompts.get_daily_prompt()

class AIChartAnalyzer:
    def __init__(self, api_key: str, stock_list_file: str = "sotck_list.txt"):
        """
        AI ì°¨íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            api_key (str): Google AI API í‚¤
            stock_list_file (str): ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        """
        self.api_key = api_key
        genai.configure(api_key=api_key)
        
        # ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì„¤ì •
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ì¢…ëª©ëª… ë§¤í¼ ì´ˆê¸°í™”
        self.stock_mapper = StockNameMapper(stock_list_file)

    def encode_image_to_base64(self, image_path: str) -> str:
        """
        ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        
        Args:
            image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
        """
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return ""

    def analyze_chart_image(self, image_path: str, stock_name: str = "", chart_type: str = "ì¼ë´‰", chart_data: Optional[pd.DataFrame] = None, 
                           json_data_path: str = "", csv_data_path: str = "", text_summary_path: str = "") -> Optional[Dict[str, Any]]:
        """
        ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ AIë¡œ ë¶„ì„ (ê°œì„ ëœ ë²„ì „ - JSON/CSV/í…ìŠ¤íŠ¸ ë°ì´í„° ì§€ì›)
        
        Args:
            image_path (str): ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            stock_name (str): ì¢…ëª©ëª…
            chart_type (str): ì°¨íŠ¸ ìœ í˜• (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰)
            chart_data (pd.DataFrame): ì°¨íŠ¸ ë°ì´í„° (Open, High, Low, Close, Volume)
            json_data_path (str): JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            csv_data_path (str): CSV ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            text_summary_path (str): í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ JSON
        """
        try:
            print(f"ğŸ” AI ì°¨íŠ¸ ë¶„ì„ ì‹œì‘: {image_path}")
            print(f"ğŸ“Š ì°¨íŠ¸ ìœ í˜•: {chart_type}")
            
            # íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì •ë³´ ì¶”ì¶œ
            filename = os.path.basename(image_path)
            extracted_stock_name, extracted_stock_code = self.stock_mapper.extract_stock_info_from_filename(filename)
            
            # ì¢…ëª©ëª…ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì¶”ì¶œëœ ì •ë³´ ì‚¬ìš©
            if not stock_name:
                stock_name = extracted_stock_name
                # ì¢…ëª©ë²ˆí˜¸ë¡œ ì •í™•í•œ ì¢…ëª©ëª… ì¡°íšŒ
                if extracted_stock_code and extracted_stock_code != "000000":
                    stock_name = self.stock_mapper.get_stock_name(extracted_stock_code)
            
            print(f"ğŸ“ˆ ì¢…ëª©ëª…: {stock_name}")
            print(f"ğŸ“ˆ ì¢…ëª©ë²ˆí˜¸: {extracted_stock_code}")
            
            # 1. ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ë° ë¬´ê²°ì„± ê²€ì¦
            if not os.path.exists(image_path):
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                return None
            
            # ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(image_path)
            print(f"ğŸ“Š ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
            
            if file_size == 0:
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {image_path}")
                return None
            
            # 2. ì´ë¯¸ì§€ í˜•ì‹ ë° í¬ê¸° ê²€ì¦
            try:
                with Image.open(image_path) as img:
                    print(f"ğŸ“Š ì´ë¯¸ì§€ í¬ê¸°: {img.size}")
                    print(f"ğŸ“Š ì´ë¯¸ì§€ í˜•ì‹: {img.format}")
                    print(f"ğŸ“Š ì´ë¯¸ì§€ ëª¨ë“œ: {img.mode}")
                    
                    # ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ê²½ê³ 
                    if img.size[0] < 100 or img.size[1] < 100:
                        print(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {img.size}")
                    
                    # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ ê³ ë ¤
                    if img.size[0] > 4000 or img.size[1] > 4000:
                        print(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {img.size}")
                        print(f"ğŸ”„ ì´ë¯¸ì§€ë¥¼ 2000x2000ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤...")
                        
                        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
                        max_size = 2000
                        if img.size[0] > img.size[1]:
                            new_width = max_size
                            new_height = int(img.size[1] * max_size / img.size[0])
                        else:
                            new_height = max_size
                            new_width = int(img.size[0] * max_size / img.size[1])
                        
                        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                        print(f"âœ… ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {img.size}")
                        
            except Exception as e:
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
                return None
            
            # 3. ì°¨íŠ¸ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            prompt = ChartAnalysisPrompts.get_prompt(chart_type)
            
            # 4. ì¶”ê°€ ë°ì´í„° íŒŒì¼ë“¤ ë¡œë“œ ë° í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            additional_data_info = self._load_additional_data_files(json_data_path, csv_data_path, text_summary_path)
            if additional_data_info:
                prompt += f"\n\n{additional_data_info}"
                print(f"âœ… ì¶”ê°€ ë°ì´í„° íŒŒì¼ ì •ë³´ê°€ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # 5. ì°¨íŠ¸ ë°ì´í„° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹)
            if chart_data is not None and not chart_data.empty:
                print(f"ğŸ“Š ì°¨íŠ¸ ë°ì´í„° ì •ë³´ ì¶”ê°€: {len(chart_data)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
                
                # ìµœê·¼ ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
                recent_data = chart_data.tail(10)  # ìµœê·¼ 10ê°œ ë°ì´í„°
                
                data_summary = f"""
**ì°¨íŠ¸ ë°ì´í„° ì •ë³´:**
- ë°ì´í„° ê¸°ê°„: {chart_data.index[0].strftime('%Y-%m-%d')} ~ {chart_data.index[-1].strftime('%Y-%m-%d')}
- ì´ ë°ì´í„° ìˆ˜: {len(chart_data)}ê°œ
- ìµœê·¼ 10ê°œ ë°ì´í„°:
"""
                
                for i, (date, row) in enumerate(recent_data.iterrows()):
                    data_summary += f"- {date.strftime('%Y-%m-%d')}: ì‹œê°€ {row['Open']:,.0f}, ê³ ê°€ {row['High']:,.0f}, ì €ê°€ {row['Low']:,.0f}, ì¢…ê°€ {row['Close']:,.0f}, ê±°ë˜ëŸ‰ {row['Volume']:,.0f}\n"
                
                # ê¸°ìˆ ì  ì§€í‘œ ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
                if 'MA5' in chart_data.columns:
                    data_summary += f"- 5ê¸°ê°„ ì´ë™í‰ê· : {chart_data['MA5'].iloc[-1]:,.0f}\n"
                if 'MA20' in chart_data.columns:
                    data_summary += f"- 20ê¸°ê°„ ì´ë™í‰ê· : {chart_data['MA20'].iloc[-1]:,.0f}\n"
                if 'RSI' in chart_data.columns:
                    data_summary += f"- RSI: {chart_data['RSI'].iloc[-1]:.1f}\n"
                if 'MACD' in chart_data.columns:
                    data_summary += f"- MACD: {chart_data['MACD'].iloc[-1]:.2f}\n"
                
                # ê°€ê²© ë³€ë™ ì •ë³´
                price_change = chart_data['Close'].iloc[-1] - chart_data['Open'].iloc[0]
                price_change_pct = (price_change / chart_data['Open'].iloc[0]) * 100
                data_summary += f"- ì „ì²´ ê¸°ê°„ ê°€ê²© ë³€ë™: {price_change:+,.0f}ì› ({price_change_pct:+.2f}%)\n"
                
                # ìµœê·¼ ë³€ë™ ì •ë³´
                recent_change = chart_data['Close'].iloc[-1] - chart_data['Close'].iloc[-2] if len(chart_data) > 1 else 0
                recent_change_pct = (recent_change / chart_data['Close'].iloc[-2]) * 100 if len(chart_data) > 1 else 0
                data_summary += f"- ìµœê·¼ ë³€ë™: {recent_change:+,.0f}ì› ({recent_change_pct:+.2f}%)\n"
                
                prompt += data_summary
                
                print(f"âœ… ì°¨íŠ¸ ë°ì´í„° ì •ë³´ê°€ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"âš ï¸ ì°¨íŠ¸ ë°ì´í„°ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì™€ ì¶”ê°€ ë°ì´í„° íŒŒì¼ë§Œìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # ì¢…ëª©ëª… ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            prompt += f"\n\n**ì¤‘ìš”: ë¶„ì„í•  ì¢…ëª©ì€ '{stock_name}' (ì¢…ëª©ë²ˆí˜¸: {extracted_stock_code})ì…ë‹ˆë‹¤.**"
            prompt = prompt.replace("[ì¢…ëª©ëª…]", stock_name)
            
            # 6. AI ë¶„ì„ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"ğŸ”„ AI ë¶„ì„ ì‹œë„ {attempt + 1}/{max_retries}")
                    
                    # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
                    image = Image.open(image_path)
                    
                    # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ
                    if image.size[0] > 2000 or image.size[1] > 2000:
                        max_size = 2000
                        if image.size[0] > image.size[1]:
                            new_width = max_size
                            new_height = int(image.size[1] * max_size / image.size[0])
                        else:
                            new_height = max_size
                            new_width = int(image.size[0] * max_size / image.size[1])
                        
                        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                        print(f"ğŸ”„ AI ë¶„ì„ìš© ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {image.size}")
                    
                    # AI ë¶„ì„ ìš”ì²­ (ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡)
                    try:
                        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                        import base64
                        import io
                        
                        # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
                        img_buffer = io.BytesIO()
                        image.save(img_buffer, format='PNG')
                        img_buffer.seek(0)
                        
                        # base64ë¡œ ì¸ì½”ë”©
                        img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
                        print(f"ğŸ“Š ì´ë¯¸ì§€ base64 ì¸ì½”ë”© ì™„ë£Œ: {len(img_base64)} ë¬¸ì")
                        
                        # AI ë¶„ì„ ìš”ì²­ (base64 ì´ë¯¸ì§€ í¬í•¨)
                        response = self.model.generate_content([
                            prompt,
                            {
                                "mime_type": "image/png",
                                "data": img_base64
                            }
                        ])
                        
                        # ì‘ë‹µì´ ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°, ë‹¤ë¥¸ ë°©ì‹ ì‹œë„
                        if "ì´ë¯¸ì§€ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ" in response.text or "ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë¯€ë¡œ" in response.text:
                            print("âš ï¸ AIê°€ ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•˜ì§€ ëª»í•¨. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„...")
                            
                            # íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ ì „ë‹¬í•˜ëŠ” ë°©ì‹ ì‹œë„
                            response = self.model.generate_content([
                                prompt + "\n\nì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ: " + image_path,
                                image
                            ])
                        
                    except Exception as e:
                        print(f"âš ï¸ base64 ì¸ì½”ë”© ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„: {e}")
                        # ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„
                        response = self.model.generate_content([
                            prompt,
                            image
                        ])
                    
                    if response.text:
                        print(f"âœ… AI ë¶„ì„ ì™„ë£Œ (ì‹œë„ {attempt + 1})")
                        print(f"ğŸ“ AI ì‘ë‹µ ê¸¸ì´: {len(response.text)}")
                        print(f"ğŸ“ AI ì‘ë‹µ ì‹œì‘: {response.text[:100]}...")
                        
                        # 7. ì‘ë‹µ ê²€ì¦ ë° JSON íŒŒì‹±
                        if self._is_valid_json_response(response.text):
                            try:
                                analysis_result = self._parse_json_response(response.text)
                                
                                # ë¶„ì„ ì¼ì‹œ ë° ì°¨íŠ¸ ìœ í˜• ì¶”ê°€
                                if "ì¢…ëª©ì •ë³´" in analysis_result:
                                    analysis_result["ì¢…ëª©ì •ë³´"]["ë¶„ì„ì¼ì‹œ"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                    analysis_result["ì¢…ëª©ì •ë³´"]["ì°¨íŠ¸ìœ í˜•"] = chart_type
                                    # ì¢…ëª©ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì¶”ê°€
                                    if "ì¢…ëª©ëª…" not in analysis_result["ì¢…ëª©ì •ë³´"]:
                                        analysis_result["ì¢…ëª©ì •ë³´"]["ì¢…ëª©ëª…"] = stock_name
                                    if "ì¢…ëª©ë²ˆí˜¸" not in analysis_result["ì¢…ëª©ì •ë³´"]:
                                        analysis_result["ì¢…ëª©ì •ë³´"]["ì¢…ëª©ë²ˆí˜¸"] = extracted_stock_code
                                else:
                                    # ì¢…ëª©ì •ë³´ ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
                                    analysis_result["ì¢…ëª©ì •ë³´"] = {
                                        "ì¢…ëª©ëª…": stock_name,
                                        "ì¢…ëª©ë²ˆí˜¸": extracted_stock_code,
                                        "ë¶„ì„ì¼ì‹œ": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                        "ì°¨íŠ¸ìœ í˜•": chart_type
                                    }
                                
                                print(f"âœ… JSON íŒŒì‹± ì„±ê³µ (ì‹œë„ {attempt + 1})")
                                return analysis_result
                                
                            except json.JSONDecodeError as e:
                                print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
                                if attempt < max_retries - 1:
                                    print(f"ğŸ”„ ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{max_retries})")
                                    time.sleep(2)
                                    continue
                                else:
                                    print(f"âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì‘ë‹µ: {response.text}")
                                    return self._create_fallback_result(stock_name, chart_type, response.text, "JSON íŒŒì‹± ì‹¤íŒ¨", extracted_stock_code)
                        else:
                            print(f"âš ï¸ AI ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤ (ì‹œë„ {attempt + 1})")
                            if attempt < max_retries - 1:
                                print(f"ğŸ”„ ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{max_retries})")
                                time.sleep(2)
                                continue
                            else:
                                print(f"âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì‘ë‹µ: {response.text}")
                                return self._create_fallback_result(stock_name, chart_type, response.text, "JSON í˜•ì‹ ì•„ë‹˜", extracted_stock_code)
                    else:
                        print(f"âŒ AI ë¶„ì„ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤ (ì‹œë„ {attempt + 1})")
                        if attempt < max_retries - 1:
                            print(f"ğŸ”„ ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{max_retries})")
                            time.sleep(2)
                            continue
                        else:
                            return None
                            
                except Exception as e:
                    print(f"âŒ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}): {e}")
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ ì¬ì‹œë„ ì¤‘... ({attempt + 2}/{max_retries})")
                        time.sleep(2)
                        continue
                    else:
                        return None
            
            return None
                
        except Exception as e:
            print(f"âŒ AI ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def _is_valid_json_response(self, response_text: str) -> bool:
        """AI ì‘ë‹µì´ ìœ íš¨í•œ JSON í˜•ì‹ì¸ì§€ í™•ì¸"""
        text = response_text.strip()
        
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±° (ë” ê°•ë ¥í•œ ë°©ì‹)
        if text.startswith('```json'):
            text = text[7:]
        elif text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        # JSON í˜•ì‹ì¸ì§€ í™•ì¸
        is_json = text.startswith('{') and text.endswith('}')
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
        print(f"ğŸ” JSON ê²€ì¦: {is_json}")
        print(f"ğŸ” ì‘ë‹µ ì‹œì‘: {text[:50]}...")
        print(f"ğŸ” ì‘ë‹µ ë: ...{text[-50:]}")
        
        return is_json
    
    def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
        """AI ì‘ë‹µì—ì„œ JSON íŒŒì‹±"""
        json_text = response_text.strip()
        
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±° (ë” ê°•ë ¥í•œ ë°©ì‹)
        if json_text.startswith('```json'):
            json_text = json_text[7:]
        elif json_text.startswith('```'):
            json_text = json_text[3:]
        if json_text.endswith('```'):
            json_text = json_text[:-3]
        
        # ì•ë’¤ ê³µë°± ì œê±°
        json_text = json_text.strip()
        
        return json.loads(json_text)
    
    def _create_fallback_result(self, stock_name: str, chart_type: str, ai_response: str, error_type: str, stock_code: str = "000000") -> Dict[str, Any]:
        """JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê²°ê³¼ ìƒì„±"""
        return {
            "ì¢…ëª©ì •ë³´": {
                "ì¢…ëª©ëª…": stock_name,
                "ì¢…ëª©ë²ˆí˜¸": stock_code,
                "ë¶„ì„ì¼ì‹œ": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "ì°¨íŠ¸ìœ í˜•": chart_type,
                "íŒŒì‹±ìƒíƒœ": error_type
            },
            "AIë¶„ì„ê²°ê³¼": ai_response
        }

    def save_analysis_result(self, result: Dict[str, Any], output_path: str) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            result (Dict[str, Any]): ë¶„ì„ ê²°ê³¼
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ JSON ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ JSON ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def create_word_document(self, result: Dict[str, Any], chart_image_path: str, output_path: str, chart_type: str = "ì¼ë´‰") -> bool:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ Word ë¬¸ì„œë¡œ ìƒì„±
        
        Args:
            result (Dict[str, Any]): ë¶„ì„ ê²°ê³¼
            chart_image_path (str): ì°¨íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
            output_path (str): ì €ì¥í•  Word íŒŒì¼ ê²½ë¡œ
            chart_type (str): ì°¨íŠ¸ ìœ í˜• (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰)
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Word ë¬¸ì„œ ìƒì„±
            doc = Document()
            
            # í•œê¸€ í°íŠ¸ ì„¤ì •ì„ ìœ„í•œ ìŠ¤íƒ€ì¼ ì„¤ì •
            from docx.oxml.ns import qn
            
            # ì œëª© ì„¤ì •
            title = doc.add_heading('AI ì£¼ì‹ ì°¨íŠ¸ ë¶„ì„ ë¦¬í¬íŠ¸', 0)
            title.alignment = WD_ALIGN_PARAGRAPH.CENTER
            # ì œëª©ì— í•œê¸€ í°íŠ¸ ì ìš©
            for run in title.runs:
                run.font.name = 'ë§‘ì€ ê³ ë”•'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # ì¢…ëª© ì •ë³´
            heading1 = doc.add_heading('ì¢…ëª© ì •ë³´', level=1)
            for run in heading1.runs:
                run.font.name = 'ë§‘ì€ ê³ ë”•'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            if "ì¢…ëª©ì •ë³´" in result:
                info = result["ì¢…ëª©ì •ë³´"]
                p1 = doc.add_paragraph(f"ì¢…ëª©ëª…: {info.get('ì¢…ëª©ëª…', 'N/A')}")
                p2 = doc.add_paragraph(f"ì¢…ëª©ë²ˆí˜¸: {info.get('ì¢…ëª©ë²ˆí˜¸', 'N/A')}")
                p3 = doc.add_paragraph(f"ë¶„ì„ì¼ì‹œ: {info.get('ë¶„ì„ì¼ì‹œ', 'N/A')}")
                p4 = doc.add_paragraph(f"ì°¨íŠ¸ìœ í˜•: {info.get('ì°¨íŠ¸ìœ í˜•', 'N/A')}")
                # í•œê¸€ í°íŠ¸ ì ìš©
                for p in [p1, p2, p3, p4]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # ì¢…í•© ë¶„ì„ ì ìˆ˜
            if "ì¢…í•©ë¶„ì„ì ìˆ˜" in result:
                heading_score = doc.add_heading('ì¢…í•© ë¶„ì„ ì ìˆ˜', level=1)
                for run in heading_score.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                score = result["ì¢…í•©ë¶„ì„ì ìˆ˜"]
                p_score1 = doc.add_paragraph(f"ì ìˆ˜: {score.get('ì ìˆ˜', 'N/A')}/100")
                p_score2 = doc.add_paragraph(f"ìš”ì•½: {score.get('ìš”ì•½', 'N/A')}")
                
                # ì ìˆ˜ ê°•ì¡°
                p_score1.runs[0].bold = True
                p_score1.runs[0].font.size = Pt(14)
                
                for p in [p_score1, p_score2]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # ì°¨íŠ¸ ì´ë¯¸ì§€ ì¶”ê°€
            heading2 = doc.add_heading('ì°¨íŠ¸ ì´ë¯¸ì§€', level=1)
            for run in heading2.runs:
                run.font.name = 'ë§‘ì€ ê³ ë”•'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            if os.path.exists(chart_image_path):
                doc.add_picture(chart_image_path, width=Inches(6))
                doc.add_paragraph()
            
            # ì˜¤ëŠ˜ì˜ ë´‰ ìš”ì•½ (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰)
            if chart_type == "ì¼ë´‰" and "ì˜¤ëŠ˜ì˜ì¼ë´‰" in result:
                heading_candle = doc.add_heading('ì˜¤ëŠ˜ì˜ ì¼ë´‰ ìš”ì•½', level=1)
                for run in heading_candle.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                candle = result["ì˜¤ëŠ˜ì˜ì¼ë´‰"]
                p_candle1 = doc.add_paragraph(f"ì¢…ê°€: {candle.get('ì¢…ê°€', 'N/A')}ì›")
                p_candle2 = doc.add_paragraph(f"ë“±ë½ë¥ : {candle.get('ë“±ë½ë¥ ', 'N/A')}%")
                p_candle3 = doc.add_paragraph(f"ê±°ë˜ëŸ‰: {candle.get('ê±°ë˜ëŸ‰', 'N/A')}ì£¼")
                p_candle4 = doc.add_paragraph(f"ì£¼ìš” íŠ¹ì§•: {candle.get('ì£¼ìš”íŠ¹ì§•', 'N/A')}")
                
                for p in [p_candle1, p_candle2, p_candle3, p_candle4]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            elif chart_type == "ì£¼ë´‰" and "ì´ë²ˆì£¼ë´‰" in result:
                heading_candle = doc.add_heading('ì´ë²ˆ ì£¼ ë´‰ ìš”ì•½', level=1)
                for run in heading_candle.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                candle = result["ì´ë²ˆì£¼ë´‰"]
                p_candle1 = doc.add_paragraph(f"ì¢…ê°€: {candle.get('ì¢…ê°€', 'N/A')}ì›")
                p_candle2 = doc.add_paragraph(f"ë“±ë½ë¥ : {candle.get('ë“±ë½ë¥ ', 'N/A')}%")
                p_candle3 = doc.add_paragraph(f"ê±°ë˜ëŸ‰: {candle.get('ê±°ë˜ëŸ‰', 'N/A')}ì£¼")
                p_candle4 = doc.add_paragraph(f"ì£¼ìš” íŠ¹ì§•: {candle.get('ì£¼ìš”íŠ¹ì§•', 'N/A')}")
                
                for p in [p_candle1, p_candle2, p_candle3, p_candle4]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            elif chart_type == "ì›”ë´‰" and "ì´ë²ˆì›”ë´‰" in result:
                heading_candle = doc.add_heading('ì´ë²ˆ ì›”ë´‰ ìš”ì•½', level=1)
                for run in heading_candle.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                candle = result["ì´ë²ˆì›”ë´‰"]
                p_candle1 = doc.add_paragraph(f"ì¢…ê°€: {candle.get('ì¢…ê°€', 'N/A')}ì›")
                p_candle2 = doc.add_paragraph(f"ë“±ë½ë¥ : {candle.get('ë“±ë½ë¥ ', 'N/A')}%")
                p_candle3 = doc.add_paragraph(f"ê±°ë˜ëŸ‰: {candle.get('ê±°ë˜ëŸ‰', 'N/A')}ì£¼")
                p_candle4 = doc.add_paragraph(f"ì£¼ìš” íŠ¹ì§•: {candle.get('ì£¼ìš”íŠ¹ì§•', 'N/A')}")
                
                for p in [p_candle1, p_candle2, p_candle3, p_candle4]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # í•µì‹¬ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ
            if "í•µì‹¬ê¸°ìˆ ì ì§€í‘œ" in result:
                heading_tech = doc.add_heading('í•µì‹¬ ê¸°ìˆ ì  ë¶„ì„ ì§€í‘œ', level=1)
                for run in heading_tech.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                tech = result["í•µì‹¬ê¸°ìˆ ì ì§€í‘œ"]
                
                # ì¼ë´‰ ì°¨íŠ¸ ì§€í‘œë“¤
                if chart_type == "ì¼ë´‰":
                    if "ì´ë™í‰ê· ì„ ì •ë°°ì—´" in tech:
                        p_tech1 = doc.add_paragraph(f"ì´ë™í‰ê· ì„  ì •ë°°ì—´: {tech.get('ì´ë™í‰ê· ì„ ì •ë°°ì—´', 'N/A')}")
                    if "ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤" in tech:
                        p_tech2 = doc.add_paragraph(f"ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤: {tech.get('ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤', 'N/A')}")
                    if "MACDìƒíƒœ" in tech:
                        p_tech3 = doc.add_paragraph(f"MACD ìƒíƒœ: {tech.get('MACDìƒíƒœ', 'N/A')}")
                    if "RSIìƒíƒœ" in tech:
                        p_tech4 = doc.add_paragraph(f"RSI ìƒíƒœ: {tech.get('RSIìƒíƒœ', 'N/A')}")
                    if "ë³¼ë¦°ì €ë°´ë“œ" in tech:
                        p_tech5 = doc.add_paragraph(f"ë³¼ë¦°ì €ë°´ë“œ: {tech.get('ë³¼ë¦°ì €ë°´ë“œ', 'N/A')}")
                
                # ì£¼ë´‰ ì°¨íŠ¸ ì§€í‘œë“¤
                elif chart_type == "ì£¼ë´‰":
                    if "ì´ë™í‰ê· ì„ ì •ë°°ì—´" in tech:
                        p_tech1 = doc.add_paragraph(f"ì´ë™í‰ê· ì„  ì •ë°°ì—´: {tech.get('ì´ë™í‰ê· ì„ ì •ë°°ì—´', 'N/A')}")
                    if "ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤" in tech:
                        p_tech2 = doc.add_paragraph(f"ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤: {tech.get('ê³¨ë“ ë°ë“œí¬ë¡œìŠ¤', 'N/A')}")
                    if "Stochasticìƒíƒœ" in tech:
                        p_tech3 = doc.add_paragraph(f"Stochastic ìƒíƒœ: {tech.get('Stochasticìƒíƒœ', 'N/A')}")
                    if "ë³¼ë¦°ì €ë°´ë“œ" in tech:
                        p_tech4 = doc.add_paragraph(f"ë³¼ë¦°ì €ë°´ë“œ: {tech.get('ë³¼ë¦°ì €ë°´ë“œ', 'N/A')}")
                
                # ì›”ë´‰ ì°¨íŠ¸ ì§€í‘œë“¤
                elif chart_type == "ì›”ë´‰":
                    if "ì¥ê¸°ì •ë°°ì—´" in tech:
                        p_tech1 = doc.add_paragraph(f"ì¥ê¸° ì •ë°°ì—´: {tech.get('ì¥ê¸°ì •ë°°ì—´', 'N/A')}")
                    if "CCIìƒíƒœ" in tech:
                        p_tech2 = doc.add_paragraph(f"CCI ìƒíƒœ: {tech.get('CCIìƒíƒœ', 'N/A')}")
                    if "ADXìƒíƒœ" in tech:
                        p_tech3 = doc.add_paragraph(f"ADX ìƒíƒœ: {tech.get('ADXìƒíƒœ', 'N/A')}")
                    if "ì£¼ìš”ì´ë™í‰ê· ì„ " in tech:
                        p_tech4 = doc.add_paragraph(f"ì£¼ìš” ì´ë™í‰ê· ì„ : {tech.get('ì£¼ìš”ì´ë™í‰ê· ì„ ', 'N/A')}")
                
                # í•œê¸€ í°íŠ¸ ì ìš©
                tech_paragraphs = []
                for i in range(1, 6):
                    if f'p_tech{i}' in locals():
                        tech_paragraphs.append(locals()[f'p_tech{i}'])
                
                for p in tech_paragraphs:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # ì„¸ë¶€ ë¶„ì„
            if "ì„¸ë¶€ë¶„ì„" in result:
                heading_detail = doc.add_heading('ì„¸ë¶€ ë¶„ì„', level=1)
                for run in heading_detail.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                detail = result["ì„¸ë¶€ë¶„ì„"]
                
                # ê°€ê²© ë° ê±°ë˜ëŸ‰ ë¶„ì„
                if "ê°€ê²©ë°ê±°ë˜ëŸ‰" in detail:
                    sub_heading1 = doc.add_heading('ê°€ê²© ë° ê±°ë˜ëŸ‰', level=2)
                    for run in sub_heading1.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                    
                    price_vol = detail["ê°€ê²©ë°ê±°ë˜ëŸ‰"]
                    if "ê±°ë˜ëŸ‰ë¹„êµ" in price_vol:
                        p_detail1 = doc.add_paragraph(f"ê±°ë˜ëŸ‰ ë¹„êµ: {price_vol.get('ê±°ë˜ëŸ‰ë¹„êµ', 'N/A')}")
                    if "ì£¼ìš”ê°€ê²©ëŒ€" in price_vol:
                        p_detail2 = doc.add_paragraph(f"ì£¼ìš” ê°€ê²©ëŒ€: {price_vol.get('ì£¼ìš”ê°€ê²©ëŒ€', 'N/A')}")
                    if "ë°•ìŠ¤ê¶Œë¶„ì„" in price_vol:
                        p_detail3 = doc.add_paragraph(f"ë°•ìŠ¤ê¶Œ ë¶„ì„: {price_vol.get('ë°•ìŠ¤ê¶Œë¶„ì„', 'N/A')}")
                    if "ì—­ì‚¬ì ê³ ì ì €ì " in price_vol:
                        p_detail4 = doc.add_paragraph(f"ì—­ì‚¬ì  ê³ ì /ì €ì : {price_vol.get('ì—­ì‚¬ì ê³ ì ì €ì ', 'N/A')}")
                
                # ì´ë™í‰ê· ì„  ë¶„ì„
                if "ì´ë™í‰ê· ì„ " in detail:
                    sub_heading2 = doc.add_heading('ì´ë™í‰ê· ì„ ', level=2)
                    for run in sub_heading2.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                    
                    ma = detail["ì´ë™í‰ê· ì„ "]
                    if "í˜„ì¬ê°€ìœ„ì¹˜" in ma:
                        p_detail5 = doc.add_paragraph(f"í˜„ì¬ê°€ ìœ„ì¹˜: {ma.get('í˜„ì¬ê°€ìœ„ì¹˜', 'N/A')}")
                    if "ë°€ì§‘ë„" in ma:
                        p_detail6 = doc.add_paragraph(f"ë°€ì§‘ë„: {ma.get('ë°€ì§‘ë„', 'N/A')}")
                    if "20ì£¼ì„ ì—­í• " in ma:
                        p_detail7 = doc.add_paragraph(f"20ì£¼ì„  ì—­í• : {ma.get('20ì£¼ì„ ì—­í• ', 'N/A')}")
                    if "20ê°œì›”ì„ ì—­í• " in ma:
                        p_detail8 = doc.add_paragraph(f"20ê°œì›”ì„  ì—­í• : {ma.get('20ê°œì›”ì„ ì—­í• ', 'N/A')}")
                
                # ëª¨ë©˜í…€ ë¶„ì„
                if "ëª¨ë©˜í…€" in detail:
                    sub_heading3 = doc.add_heading('ëª¨ë©˜í…€ ë° ê°•ë„', level=2)
                    for run in sub_heading3.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                    
                    momentum = detail["ëª¨ë©˜í…€"]
                    if "MACDë¶„ì„" in momentum:
                        p_detail9 = doc.add_paragraph(f"MACD ë¶„ì„: {momentum.get('MACDë¶„ì„', 'N/A')}")
                    if "RSIë¶„ì„" in momentum:
                        p_detail10 = doc.add_paragraph(f"RSI ë¶„ì„: {momentum.get('RSIë¶„ì„', 'N/A')}")
                    if "Stochasticë¶„ì„" in momentum:
                        p_detail11 = doc.add_paragraph(f"Stochastic ë¶„ì„: {momentum.get('Stochasticë¶„ì„', 'N/A')}")
                    if "ë³¼ë¦°ì €ë°´ë“œë¶„ì„" in momentum:
                        p_detail12 = doc.add_paragraph(f"ë³¼ë¦°ì €ë°´ë“œ ë¶„ì„: {momentum.get('ë³¼ë¦°ì €ë°´ë“œë¶„ì„', 'N/A')}")
                    if "CCIë¶„ì„" in momentum:
                        p_detail13 = doc.add_paragraph(f"CCI ë¶„ì„: {momentum.get('CCIë¶„ì„', 'N/A')}")
                    if "ADXë¶„ì„" in momentum:
                        p_detail14 = doc.add_paragraph(f"ADX ë¶„ì„: {momentum.get('ADXë¶„ì„', 'N/A')}")
                
                # ì„¸ë¶€ ë¶„ì„ í•œê¸€ í°íŠ¸ ì ìš©
                detail_paragraphs = []
                for i in range(1, 15):
                    if f'p_detail{i}' in locals():
                        detail_paragraphs.append(locals()[f'p_detail{i}'])
                
                for p in detail_paragraphs:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            # íˆ¬ì ì•„ì´ë””ì–´
            if chart_type == "ì¼ë´‰" and "ë‹¨ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                heading_idea = doc.add_heading('ë‹¨ê¸° íˆ¬ì ì•„ì´ë””ì–´', level=1)
                for run in heading_idea.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                idea = result["ë‹¨ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                if "ì¶”ì„¸ìš”ì•½" in idea:
                    p_idea1 = doc.add_paragraph(f"ì¶”ì„¸ ìš”ì•½: {idea.get('ì¶”ì„¸ìš”ì•½', 'N/A')}")
                if "ë§¤ë§¤ì‹œê·¸ë„" in idea:
                    p_idea2 = doc.add_paragraph(f"ë§¤ë§¤ ì‹œê·¸ë„: {idea.get('ë§¤ë§¤ì‹œê·¸ë„', 'N/A')}")
                    p_idea2.runs[0].bold = True
                    p_idea2.runs[0].font.size = Pt(14)
                
                for p in [p_idea1, p_idea2]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            elif chart_type == "ì£¼ë´‰" and "ì¤‘ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                heading_idea = doc.add_heading('ì¤‘ê¸° íˆ¬ì ì•„ì´ë””ì–´', level=1)
                for run in heading_idea.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                idea = result["ì¤‘ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                if "ì¶”ì„¸ìš”ì•½" in idea:
                    p_idea1 = doc.add_paragraph(f"ì¶”ì„¸ ìš”ì•½: {idea.get('ì¶”ì„¸ìš”ì•½', 'N/A')}")
                if "ë§¤ë§¤ì‹œê·¸ë„" in idea:
                    p_idea2 = doc.add_paragraph(f"ë§¤ë§¤ ì‹œê·¸ë„: {idea.get('ë§¤ë§¤ì‹œê·¸ë„', 'N/A')}")
                    p_idea2.runs[0].bold = True
                    p_idea2.runs[0].font.size = Pt(14)
                
                for p in [p_idea1, p_idea2]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            
            elif chart_type == "ì›”ë´‰" and "ì¥ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                heading_idea = doc.add_heading('ì¥ê¸° íˆ¬ì ì•„ì´ë””ì–´', level=1)
                for run in heading_idea.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
                
                idea = result["ì¥ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                if "ì‚¬ì´í´ìš”ì•½" in idea:
                    p_idea1 = doc.add_paragraph(f"ì‚¬ì´í´ ìš”ì•½: {idea.get('ì‚¬ì´í´ìš”ì•½', 'N/A')}")
                if "íˆ¬ìì „ëµ" in idea:
                    p_idea2 = doc.add_paragraph(f"íˆ¬ì ì „ëµ: {idea.get('íˆ¬ìì „ëµ', 'N/A')}")
                    p_idea2.runs[0].bold = True
                    p_idea2.runs[0].font.size = Pt(14)
                
                for p in [p_idea1, p_idea2]:
                    for run in p.runs:
                        run.font.name = 'ë§‘ì€ ê³ ë”•'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'ë§‘ì€ ê³ ë”•')
            

            
            # ë¬¸ì„œ ì €ì¥
            doc.save(output_path)
            print(f"ğŸ“„ Word ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ Word ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _load_additional_data_files(self, json_data_path: str, csv_data_path: str, text_summary_path: str) -> str:
        """
        ì¶”ê°€ ë°ì´í„° íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            json_data_path (str): JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            csv_data_path (str): CSV ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            text_summary_path (str): í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•  ë°ì´í„° ì •ë³´ í…ìŠ¤íŠ¸
        """
        additional_info = ""
        
        # 1. JSON ë°ì´í„° íŒŒì¼ ë¡œë“œ
        if json_data_path and os.path.exists(json_data_path):
            try:
                print(f"ğŸ“Š JSON ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {json_data_path}")
                with open(json_data_path, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                
                # JSON ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                json_info = f"""
**JSON êµ¬ì¡°í™” ë°ì´í„° ì •ë³´:**
- ì¢…ëª©ëª…: {json_data.get('metadata', {}).get('stock_name', 'N/A')}
- ì¢…ëª©ì½”ë“œ: {json_data.get('metadata', {}).get('stock_code', 'N/A')}
- ë°ì´í„° ê¸°ê°„: {json_data.get('metadata', {}).get('data_period', {}).get('start', 'N/A')} ~ {json_data.get('metadata', {}).get('data_period', {}).get('end', 'N/A')}
- ì´ ë°ì´í„° ìˆ˜: {json_data.get('metadata', {}).get('total_records', 'N/A')}ê°œ

**ìš”ì•½ ì •ë³´:**
- ìµœê·¼ ì¢…ê°€: {json_data.get('summary', {}).get('latest_close', 'N/A'):,.0f}ì›
- ìµœê·¼ ê±°ë˜ëŸ‰: {json_data.get('summary', {}).get('latest_volume', 'N/A'):,}ì£¼
- ê°€ê²© ë³€ë™: {json_data.get('summary', {}).get('price_change', 'N/A'):+,.0f}ì›
- ë³€ë™ë¥ : {json_data.get('summary', {}).get('price_change_pct', 'N/A'):+.2f}%
- ìµœê³ ê°€: {json_data.get('summary', {}).get('highest_price', 'N/A'):,.0f}ì›
- ìµœì €ê°€: {json_data.get('summary', {}).get('lowest_price', 'N/A'):,.0f}ì›
- í‰ê·  ê±°ë˜ëŸ‰: {json_data.get('summary', {}).get('avg_volume', 'N/A'):,.0f}ì£¼

**ê¸°ìˆ ì  ì§€í‘œ (ìµœê·¼ê°’):**
"""
                
                # ê¸°ìˆ ì  ì§€í‘œ ì •ë³´ ì¶”ê°€
                tech_indicators = json_data.get('technical_indicators', {}).get('latest_values', {})
                for indicator, value in tech_indicators.items():
                    if value is not None:
                        if 'ma' in indicator.lower():
                            json_info += f"- {indicator.upper()}: {value:,.0f}ì›\n"
                        else:
                            json_info += f"- {indicator.upper()}: {value:.2f}\n"
                
                # ìµœê·¼ ì°¨íŠ¸ ë°ì´í„° (ìµœëŒ€ 5ê°œ)
                chart_data = json_data.get('chart_data', [])
                if chart_data:
                    json_info += f"\n**ìµœê·¼ 5ê°œ ê±°ë˜ì¼ ë°ì´í„°:**\n"
                    for i, data_point in enumerate(chart_data[-5:]):
                        json_info += f"- {data_point['date']}: ì‹œê°€ {data_point['open']:,.0f}, ê³ ê°€ {data_point['high']:,.0f}, ì €ê°€ {data_point['low']:,.0f}, ì¢…ê°€ {data_point['close']:,.0f}, ê±°ë˜ëŸ‰ {data_point['volume']:,}\n"
                
                additional_info += json_info
                print(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ JSON ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 2. CSV ë°ì´í„° íŒŒì¼ ë¡œë“œ
        if csv_data_path and os.path.exists(csv_data_path):
            try:
                print(f"ğŸ“Š CSV ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘: {csv_data_path}")
                import pandas as pd
                csv_data = pd.read_csv(csv_data_path, encoding='utf-8-sig')
                
                csv_info = f"""
**CSV ë°ì´í„° ì •ë³´:**
- íŒŒì¼ ê²½ë¡œ: {csv_data_path}
- ë°ì´í„° ìˆ˜: {len(csv_data)}ê°œ
- ì»¬ëŸ¼: {', '.join(csv_data.columns.tolist())}

**ìµœê·¼ 5ê°œ ë°ì´í„°:**
"""
                
                # ìµœê·¼ 5ê°œ ë°ì´í„° ì¶”ê°€
                for i, row in csv_data.tail(5).iterrows():
                    csv_info += f"- {row.iloc[0]}: ì‹œê°€ {row['Open']:,.0f}, ê³ ê°€ {row['High']:,.0f}, ì €ê°€ {row['Low']:,.0f}, ì¢…ê°€ {row['Close']:,.0f}, ê±°ë˜ëŸ‰ {row['Volume']:,}\n"
                
                additional_info += csv_info
                print(f"âœ… CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ CSV ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ë¡œë“œ
        if text_summary_path and os.path.exists(text_summary_path):
            try:
                print(f"ğŸ“Š í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ë¡œë“œ ì¤‘: {text_summary_path}")
                with open(text_summary_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()
                
                text_info = f"""
**í…ìŠ¤íŠ¸ ìš”ì•½ ì •ë³´:**
{text_content}
"""
                
                additional_info += text_info
                print(f"âœ… í…ìŠ¤íŠ¸ ìš”ì•½ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return additional_info

    def analyze_chart_with_data_files(self, image_path: str, json_data_path: str = "", csv_data_path: str = "", 
                                     text_summary_path: str = "", stock_name: str = "", chart_type: str = "ì¼ë´‰") -> Optional[Dict[str, Any]]:
        """
        ì°¨íŠ¸ ì´ë¯¸ì§€ì™€ ë°ì´í„° íŒŒì¼ë“¤ì„ í•¨ê»˜ AIë¡œ ë¶„ì„í•˜ëŠ” í¸ì˜ ë©”ì„œë“œ
        
        Args:
            image_path (str): ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            json_data_path (str): JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            csv_data_path (str): CSV ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            text_summary_path (str): í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
            stock_name (str): ì¢…ëª©ëª…
            chart_type (str): ì°¨íŠ¸ ìœ í˜• (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰)
            
        Returns:
            Dict[str, Any]: ë¶„ì„ ê²°ê³¼ JSON
        """
        print(f"ğŸš€ ì°¨íŠ¸ ì´ë¯¸ì§€ì™€ ë°ì´í„° íŒŒì¼ë“¤ì„ í•¨ê»˜ ë¶„ì„í•©ë‹ˆë‹¤...")
        print(f"ğŸ“ˆ ì°¨íŠ¸ ì´ë¯¸ì§€: {image_path}")
        print(f"ğŸ“Š JSON ë°ì´í„°: {json_data_path if json_data_path else 'ì—†ìŒ'}")
        print(f"ğŸ“‹ CSV ë°ì´í„°: {csv_data_path if csv_data_path else 'ì—†ìŒ'}")
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ìš”ì•½: {text_summary_path if text_summary_path else 'ì—†ìŒ'}")
        
        return self.analyze_chart_image(
            image_path=image_path,
            stock_name=stock_name,
            chart_type=chart_type,
            json_data_path=json_data_path,
            csv_data_path=csv_data_path,
            text_summary_path=text_summary_path
        )

    def find_related_data_files(self, image_path: str) -> tuple:
        """
        ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ê³¼ ê´€ë ¨ëœ ë°ì´í„° íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ì°¾ê¸°
        
        Args:
            image_path (str): ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            tuple: (json_path, csv_path, text_path)
        """
        print(f"ğŸ” ê´€ë ¨ ë°ì´í„° íŒŒì¼ë“¤ì„ ì°¾ëŠ” ì¤‘: {image_path}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        image_filename = os.path.basename(image_path)
        image_name_without_ext = os.path.splitext(image_filename)[0]
        
        # íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ëª…ê³¼ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
        parts = image_name_without_ext.split('_')
        if len(parts) >= 3:
            chart_type = parts[0]  # daily, weekly, monthly
            stock_name = parts[1]
            stock_code = parts[2]
            date_part = parts[3] if len(parts) > 3 else ""
        else:
            print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ëª… í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_filename}")
            return "", "", ""
        
        # ê´€ë ¨ íŒŒì¼ë“¤ ì°¾ê¸°
        json_path = ""
        csv_path = ""
        text_path = ""
        
        # 1. JSON íŒŒì¼ ì°¾ê¸°
        json_pattern = f"{chart_type}_{stock_name}_{stock_code}_{date_part}.json"
        json_dir = "chart_data_json"
        if os.path.exists(json_dir):
            for file in os.listdir(json_dir):
                if file.startswith(f"{chart_type}_{stock_name}_{stock_code}_{date_part}"):
                    json_path = os.path.join(json_dir, file)
                    break
        
        # 2. CSV íŒŒì¼ ì°¾ê¸°
        csv_pattern = f"{chart_type}_{stock_name}_{stock_code}_{date_part}.csv"
        csv_dir = "chart_data_csv"
        if os.path.exists(csv_dir):
            for file in os.listdir(csv_dir):
                if file.startswith(f"{chart_type}_{stock_name}_{stock_code}_{date_part}"):
                    csv_path = os.path.join(csv_dir, file)
                    break
        
        # 3. í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ì°¾ê¸°
        text_pattern = f"{chart_type}_{stock_name}_{stock_code}_{date_part}_summary.txt"
        text_dir = "chart_data_text"
        if os.path.exists(text_dir):
            for file in os.listdir(text_dir):
                if file.startswith(f"{chart_type}_{stock_name}_{stock_code}_{date_part}_summary"):
                    text_path = os.path.join(text_dir, file)
                    break
        
        print(f"ğŸ“Š ì°¾ì€ ê´€ë ¨ íŒŒì¼ë“¤:")
        print(f"   JSON: {json_path if json_path else 'ì—†ìŒ'}")
        print(f"   CSV: {csv_path if csv_path else 'ì—†ìŒ'}")
        print(f"   í…ìŠ¤íŠ¸: {text_path if text_path else 'ì—†ìŒ'}")
        
        return json_path, csv_path, text_path

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ï¿½ï¿½ AI ì œë¯¸ë‚˜ì´ ì°¨íŠ¸ ë¶„ì„ í”„ë¡œê·¸ë¨ (ê°œì„ ëœ ë²„ì „)")
    print("="*60)
    
    # ì„¤ì • íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
    from config import config
    
    api_key = config.get_api_key()
    if not api_key:
        print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("Google AI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:")
        print("(https://makersuite.google.com/app/apikey ì—ì„œ ë°œê¸‰ ê°€ëŠ¥)")
        
        api_key = input("ğŸ”‘ Google AI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not api_key:
            print("âŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        # API í‚¤ ì €ì¥
        if config.set_api_key(api_key):
            print("âœ… API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ API í‚¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # AI ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = AIChartAnalyzer(api_key)
    
    # ì°¨íŠ¸ í´ë”ë“¤ í™•ì¸
    chart_folders = ["daily_charts", "weekly_charts", "monthly_charts"]
    available_folders = []
    
    for folder in chart_folders:
        if os.path.exists(folder):
            chart_files = [f for f in os.listdir(folder) if f.endswith('.png')]
            if chart_files:
                available_folders.append((folder, chart_files))
    
    if not available_folders:
        print("âŒ ì°¨íŠ¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € ì°¨íŠ¸ ìƒì„± í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•˜ì—¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    print("ğŸ“ ë°œê²¬ëœ ì°¨íŠ¸ íŒŒì¼ë“¤:")
    file_index = 1
    file_mapping = {}
    
    for folder, files in available_folders:
        chart_type = folder.replace("_charts", "")
        print(f"\nğŸ“Š {chart_type} ì°¨íŠ¸:")
        for file in files:
            print(f"  {file_index}. {file}")
            file_mapping[file_index] = (folder, file, chart_type)
            file_index += 1
    
    # ë¶„ì„í•  íŒŒì¼ ì„ íƒ
    while True:
        try:
            choice = input(f"\nğŸ“Š ë¶„ì„í•  ì°¨íŠ¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(file_mapping)}): ").strip()
            file_index = int(choice)
            
            if file_index in file_mapping:
                folder, selected_file, chart_type = file_mapping[file_index]
                break
            else:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    image_path = os.path.join(folder, selected_file)
    
    print(f"\nğŸ” ë¶„ì„ ì‹œì‘: {selected_file}")
    print(f"ğŸ“ íŒŒì¼: {image_path}")
    print(f"ğŸ“Š ì°¨íŠ¸ ìœ í˜•: {chart_type}")
    
    # ê´€ë ¨ ë°ì´í„° íŒŒì¼ë“¤ ìë™ ì°¾ê¸°
    print(f"\nğŸ” ê´€ë ¨ ë°ì´í„° íŒŒì¼ë“¤ì„ ì°¾ëŠ” ì¤‘...")
    json_path, csv_path, text_path = analyzer.find_related_data_files(image_path)
    
    # ë¶„ì„ ëª¨ë“œ ì„ íƒ
    print(f"\nğŸ“Š ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print(f"1. ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ë¶„ì„ (ê¸°ë³¸)")
    print(f"2. ì´ë¯¸ì§€ + ë°ì´í„° íŒŒì¼ë“¤ê³¼ í•¨ê»˜ ë¶„ì„ (ê¶Œì¥)")
    
    while True:
        try:
            mode_choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
            if mode_choice in ['1', '2']:
                break
            else:
                print("âŒ 1 ë˜ëŠ” 2ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # AI ë¶„ì„ ì‹¤í–‰
    if mode_choice == '1':
        print(f"\nğŸ“Š ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        result = analyzer.analyze_chart_image(image_path, "", chart_type)
    else:
        print(f"\nğŸ“Š ì´ë¯¸ì§€ì™€ ë°ì´í„° íŒŒì¼ë“¤ì„ í•¨ê»˜ ë¶„ì„í•©ë‹ˆë‹¤...")
        if json_path or csv_path or text_path:
            print(f"âœ… ê´€ë ¨ ë°ì´í„° íŒŒì¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            result = analyzer.analyze_chart_with_data_files(
                image_path=image_path,
                json_data_path=json_path,
                csv_data_path=csv_path,
                text_summary_path=text_path,
                stock_name="",
                chart_type=chart_type
            )
        else:
            print(f"âš ï¸ ê´€ë ¨ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
            result = analyzer.analyze_chart_image(image_path, "", chart_type)
    
    if result:
        # ê²°ê³¼ ì €ì¥
        output_dir = "ai_analysis_results"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"ğŸ“ {output_dir} í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì¢…ëª©ì •ë³´ ì¶”ì¶œ
        stock_info = result.get("ì¢…ëª©ì •ë³´", {})
        stock_name = stock_info.get("ì¢…ëª©ëª…", "unknown")
        stock_code = stock_info.get("ì¢…ëª©ë²ˆí˜¸", "000000")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"analysis_{chart_type}_{stock_name}_{stock_code}_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        # Word ë¬¸ì„œ ì €ì¥
        doc_filename = f"analysis_{chart_type}_{stock_name}_{stock_code}_{timestamp}.docx"
        doc_path = os.path.join(output_dir, doc_filename)
        
        # JSON íŒŒì¼ ì €ì¥
        json_success = analyzer.save_analysis_result(result, json_path)
        
        # Word ë¬¸ì„œ ìƒì„±
        doc_success = analyzer.create_word_document(result, image_path, doc_path, chart_type)
        
        if json_success and doc_success:
            print("\nâœ… AI ì°¨íŠ¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“„ JSON ê²°ê³¼ íŒŒì¼: {json_path}")
            print(f"ğŸ“„ Word ë¬¸ì„œ íŒŒì¼: {doc_path}")
            
            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if "ì¢…í•©ë¶„ì„ì ìˆ˜" in result:
                score = result["ì¢…í•©ë¶„ì„ì ìˆ˜"]
                print(f"\nğŸ“Š ì¢…í•© ë¶„ì„ ì ìˆ˜: {score.get('ì ìˆ˜', 'N/A')}/100")
                print(f"ğŸ“ ìš”ì•½: {score.get('ìš”ì•½', 'N/A')}")
            
            # íˆ¬ì ì•„ì´ë””ì–´ ì¶œë ¥
            if chart_type == "ì¼ë´‰" and "ë‹¨ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                idea = result["ë‹¨ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                print(f"\nğŸ“ˆ ë‹¨ê¸° íˆ¬ì ì•„ì´ë””ì–´:")
                print(f"   ì¶”ì„¸ ìš”ì•½: {idea.get('ì¶”ì„¸ìš”ì•½', 'N/A')}")
                print(f"   ë§¤ë§¤ ì‹œê·¸ë„: {idea.get('ë§¤ë§¤ì‹œê·¸ë„', 'N/A')}")
            elif chart_type == "ì£¼ë´‰" and "ì¤‘ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                idea = result["ì¤‘ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                print(f"\nğŸ“ˆ ì¤‘ê¸° íˆ¬ì ì•„ì´ë””ì–´:")
                print(f"   ì¶”ì„¸ ìš”ì•½: {idea.get('ì¶”ì„¸ìš”ì•½', 'N/A')}")
                print(f"   ë§¤ë§¤ ì‹œê·¸ë„: {idea.get('ë§¤ë§¤ì‹œê·¸ë„', 'N/A')}")
            elif chart_type == "ì›”ë´‰" and "ì¥ê¸°íˆ¬ìì•„ì´ë””ì–´" in result:
                idea = result["ì¥ê¸°íˆ¬ìì•„ì´ë””ì–´"]
                print(f"\nğŸ“ˆ ì¥ê¸° íˆ¬ì ì•„ì´ë””ì–´:")
                print(f"   ì‚¬ì´í´ ìš”ì•½: {idea.get('ì‚¬ì´í´ìš”ì•½', 'N/A')}")
                print(f"   íˆ¬ì ì „ëµ: {idea.get('íˆ¬ìì „ëµ', 'N/A')}")
        else:
            if not json_success:
                print("âŒ JSON ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            if not doc_success:
                print("âŒ Word ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

def analyze_single_chart_with_data(image_path: str, json_data_path: str = "", csv_data_path: str = "", 
                                  text_summary_path: str = "", chart_type: str = "ì¼ë´‰"):
    """
    ë‹¨ì¼ ì°¨íŠ¸ë¥¼ ë°ì´í„° íŒŒì¼ë“¤ê³¼ í•¨ê»˜ ë¶„ì„í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        image_path (str): ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        json_data_path (str): JSON ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        csv_data_path (str): CSV ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        text_summary_path (str): í…ìŠ¤íŠ¸ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
        chart_type (str): ì°¨íŠ¸ ìœ í˜• (ì¼ë´‰/ì£¼ë´‰/ì›”ë´‰)
    """
    print("ğŸ¤– AI ì œë¯¸ë‚˜ì´ ì°¨íŠ¸ ë¶„ì„ í”„ë¡œê·¸ë¨ (ë‹¨ì¼ íŒŒì¼ ë¶„ì„)")
    print("="*60)
    
    # ì„¤ì • íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
    from config import config
    
    api_key = config.get_api_key()
    if not api_key:
        print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # AI ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = AIChartAnalyzer(api_key)
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(image_path):
        print(f"âŒ ì°¨íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return None
    
    print(f"ğŸ” ë¶„ì„ ì‹œì‘: {os.path.basename(image_path)}")
    print(f"ğŸ“ íŒŒì¼: {image_path}")
    print(f"ğŸ“Š ì°¨íŠ¸ ìœ í˜•: {chart_type}")
    
    # AI ë¶„ì„ ì‹¤í–‰
    result = analyzer.analyze_chart_with_data_files(
        image_path=image_path,
        json_data_path=json_data_path,
        csv_data_path=csv_data_path,
        text_summary_path=text_summary_path,
        stock_name="",
        chart_type=chart_type
    )
    
    if result:
        # ê²°ê³¼ ì €ì¥
        output_dir = "ai_analysis_results"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì¢…ëª©ì •ë³´ ì¶”ì¶œ
        stock_info = result.get("ì¢…ëª©ì •ë³´", {})
        stock_name = stock_info.get("ì¢…ëª©ëª…", "unknown")
        stock_code = stock_info.get("ì¢…ëª©ë²ˆí˜¸", "000000")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"analysis_{chart_type}_{stock_name}_{stock_code}_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        # Word ë¬¸ì„œ ì €ì¥
        doc_filename = f"analysis_{chart_type}_{stock_name}_{stock_code}_{timestamp}.docx"
        doc_path = os.path.join(output_dir, doc_filename)
        
        # JSON íŒŒì¼ ì €ì¥
        json_success = analyzer.save_analysis_result(result, json_path)
        
        # Word ë¬¸ì„œ ìƒì„±
        doc_success = analyzer.create_word_document(result, image_path, doc_path, chart_type)
        
        if json_success and doc_success:
            print("\nâœ… AI ì°¨íŠ¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“„ JSON ê²°ê³¼ íŒŒì¼: {json_path}")
            print(f"ğŸ“„ Word ë¬¸ì„œ íŒŒì¼: {doc_path}")
            return result
        else:
            print("âŒ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None
    else:
        print("âŒ AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None

if __name__ == "__main__":
    main() 